---
type: blog
title: 电商数仓 V2.0 （02 业务数据采集模块）
date: 2021-01-19
categories: 教程
tags: 数仓
cover: false
meta:
  date: false
---

# 电商数仓 V2.0 （02 业务数据采集模块）

## 一、电商业务简介

## 二、业务数据采集模块

### 2.1 MySQL

装一台机器就行 hadoop102

### 2.2 Sqoop

- 修改配置`sqoop-env.sh`

```bash
# 目前用于将数据从 MySQL 导入 HDFS 配置下面这俩就可以
export HADOOP_COMMON_HOME=/opt/module/hadoop-2.7.2
export HADOOP_MAPRED_HOME=/opt/module/hadoop-2.7.2

# 导入 Hive 要配置 Hive_HOME；导入 HBase 要配置 HBASE_HOME 和 ZOOCFGDIR
#export HBASE_HOME=
#export HIVE_HOME=
#export ZOOCFGDIR=
```

- 拷贝 mysql jar 包

```bash
cp mysql-connector-java-5.1.27-bin.jar $SQOOP_HOME/lib
```

- 验证安装情况

```bash
$ bin/sqoop help
Available commands:
  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  eval               Evaluate a SQL statement and display the results
  export             Export an HDFS directory to a database table
  help               List available commands
  import             Import a table from a database to HDFS
  import-all-tables  Import tables from a database to HDFS
  import-mainframe   Import datasets from a mainframe server to HDFS
  job                Work with saved jobs
  list-databases     List available databases on a server
  list-tables        List available tables in a database
  merge              Merge results of incremental imports
  metastore          Run a standalone Sqoop metastore
  version            Display version information

See 'sqoop help COMMAND' for information on a specific command.
```

- 测试连接 mysql

```bash
bin/sqoop list-databases --connect jdbc:mysql://hadoop102:3306/ --username root --password 123456
# 能出现表名就是正确的了
```

### 2.3 业务数据生成

- 通过建表语句导入数据

```bash
gmall2020-03-16.sql
```

- java 生成业务数据

拷贝 `application.properties` 和 `gmall-mock-db-2020-03-16-SNAPSHOT.jar`

修改 `application.properties`

```bash
# 先生成 2020-03-10 clear=1（清空之前sql语句生成的数据），再生成 03-11 clear=0
# 业务日期
mock.date=2020-03-11
# 是否重置
mock.clear=1
```

生成数据

```bash
java -jar gmall-mock-db-2020-03-16-SNAPSHOT.jar
```

### 2.4 同步策略

数据同步策略的类型包括：**全量表、增量表、新增及变化表**

- 全量表：存储完整的数据。

- 增量表：存储新增加的数据。

- 新增及变化表：存储新增加的数据和变化的数据。

- 特殊表：只需要存储一次。

#### 2.4.1 全量同步策略

每日存入一份完整数据，作为一个分区

适用场景：表数据量不大（如小于10万），每天既有新增，也有修改的场景

例子：品牌表、优惠规则、活动、商品分类等

#### 2.4.2 增量同步策略

每天存储一份增量数据作为一个分区

适用场景：表数据量大（十万、百万以上），且每天只有新增数据，不会修改原来的数据

例子：退单表、订单状态表、商品评论表等

#### 2.4.3 新增及变化策略

每日新增及变化，就是存储创建时间和操作时间都是今天的数据

适用场景：表的数据量大，既会有新增，又会有变化

例子：用户表、订单表、优惠卷领用表

#### 2.4.4 特殊策略

某些特殊的维度表，可不必遵循上述同步策略，如一共只存储一次。

1）客观世界维度

没变化的客观世界的维度（比如性别，地区，民族，政治成分，鞋子尺码）可以只存一份固定值。

2）日期维度

日期维度可以一次性导入一年或若干年的数据。

3）地区维度

省份表、地区表

#### 2.5 业务数据导入 HDFS

- 使用 sqoop 工具
- 时间处理：T + 1模式，即后一天导入前一天的数据
- 导表类型：
  - 全量：`select * from table where 1=1`（1=1 是为了适应 Sqoop 中 `and  $CONDITIONS`的语法）
  - 增量：`select * from table where createtime paytime = $cur_date`
  - 新增和变化：``select * from table where createtime or operatetime = $cur_date`

**执行脚本：**

- 内容略
- 执行：
  - 参数：
    - 参数1：first or all，表示第一次或每日，first会导入两个地区表，all就不导入了
    - 参数2：日期
  - `mysql_to_hdfs.sh first 2020-03-10`
  - `mysql_to_hdfs.sh all 2020-03-11`
  - 一天的数据导入大概20分钟

