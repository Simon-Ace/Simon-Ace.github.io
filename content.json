{"meta":{"title":"Rookie的博客","subtitle":"Stay hungry. Stay foolish.","description":null,"author":"Simon","url":"https://simon-ace.github.io","root":"/"},"pages":[],"posts":[{"title":"将console输出到文件","slug":"将console输出到文件","date":"2020-10-08T16:00:00.000Z","updated":"2020-10-09T10:05:02.599Z","comments":true,"path":"2020/10/09/将console输出到文件/","link":"","permalink":"https://simon-ace.github.io/2020/10/09/将console输出到文件/","excerpt":"1some_command 2&gt;&amp;1 | tee output.txt","text":"1some_command 2&gt;&amp;1 | tee output.txt 在Linux中，如果想将一个程序在控制台中的输出字符输出到文件中，不保留控制台内的文字，可以用下面命令： 1some_command &gt; output.txt 命令结果会输出到output.txt中，换成&gt;&gt;可以追加到文件末尾 但如果想输出到文件同时，保留控制台的内容，需要使用tee命令，示例如下： 1some_command | tee output.txt 有时会发现上述命令后屏幕有输出，但文件内容为空，此时可能是由于some_command输出的字符从std error文件描述符输出，需要先将std error的输出导向到std output： 1some_command 2&gt;&amp;1 | tee output.txt 其中，2代表std error，1代表std output，&gt;&amp;是linux中fd到fd的重定向操作符。","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/tags/教程/"}]},{"title":"SpringBoot 集成 Prometheus","slug":"SpringBoot集成Prometheus","date":"2020-09-22T16:00:00.000Z","updated":"2020-09-25T12:14:05.812Z","comments":true,"path":"2020/09/23/SpringBoot集成Prometheus/","link":"","permalink":"https://simon-ace.github.io/2020/09/23/SpringBoot集成Prometheus/","excerpt":"","text":"一、添加依赖 Maven pom.xml 12345678910111213&lt;!-- 第一条必须加，否则会导致 Could not autowire. No beans of 'xxxx' type found 的错误 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-core&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.micrometer&lt;/groupId&gt; &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;&lt;/dependency&gt; Gradle build.gradle 123implementation &apos;org.springframework.boot:spring-boot-starter-actuator&apos;compile &apos;io.micrometer:micrometer-registry-prometheus&apos;compile &apos;io.micrometer:micrometer-core&apos; 打开 Prometheus 监控接口 application.properties 1234server.port=8088spring.application.name=springboot2-prometheusmanagement.endpoints.web.exposure.include=*management.metrics.tags.application=$&#123;spring.application.name&#125; 可以直接运行程序，访问http://localhost:8088/actuator/prometheus可以看到下面的内容： 12345678910111213141516171819202122# HELP jvm_buffer_total_capacity_bytes An estimate of the total capacity of the buffers in this pool# TYPE jvm_buffer_total_capacity_bytes gaugejvm_buffer_total_capacity_bytes&#123;id=&quot;direct&quot;,&#125; 90112.0jvm_buffer_total_capacity_bytes&#123;id=&quot;mapped&quot;,&#125; 0.0# HELP tomcat_sessions_expired_sessions_total # TYPE tomcat_sessions_expired_sessions_total countertomcat_sessions_expired_sessions_total 0.0# HELP jvm_classes_unloaded_classes_total The total number of classes unloaded since the Java virtual machine has started execution# TYPE jvm_classes_unloaded_classes_total counterjvm_classes_unloaded_classes_total 1.0# HELP jvm_buffer_count_buffers An estimate of the number of buffers in the pool# TYPE jvm_buffer_count_buffers gaugejvm_buffer_count_buffers&#123;id=&quot;direct&quot;,&#125; 11.0jvm_buffer_count_buffers&#123;id=&quot;mapped&quot;,&#125; 0.0# HELP system_cpu_usage The &quot;recent cpu usage&quot; for the whole system# TYPE system_cpu_usage gaugesystem_cpu_usage 0.0939447637893599# HELP jvm_gc_max_data_size_bytes Max size of old generation memory pool# TYPE jvm_gc_max_data_size_bytes gaugejvm_gc_max_data_size_bytes 2.841116672E9# 此处省略超多字... 二、Prometheus 安装与配置使用 docker 运行 Prometheus（仅初始测试） 1docker run --name prometheus -d -p 9090:9090 prom/prometheus:latest 写配置文件prometheus.yml 12345678910111213141516171819202122232425262728293031# my global configglobal: scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute. evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute. # scrape_timeout is set to the global default (10s).# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.rule_files: # - \"first_rules.yml\" # - \"second_rules.yml\"# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.scrape_configs: # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config. - job_name: 'prometheus' # metrics_path defaults to '/metrics' # scheme defaults to 'http'. static_configs: - targets: ['localhost:9090'] # demo job - job_name: 'springboot-actuator-prometheus-test' # job name metrics_path: '/actuator/prometheus' # 指标获取路径 scrape_interval: 5s # 间隔 basic_auth: # Spring Security basic auth username: 'actuator' password: 'actuator' static_configs: - targets: ['docker.for.mac.localhost:18080'] # 实例的地址，默认的协议是http （这里开始有问题，直接写 localhost 是访问容器内的地址，而不是宿主机的。可通过在网页上方 status -&gt; targets 查看对应的服务情况 运行 docker 1docker run -d -p 9090:9090 -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml 访问 http://localhost:9090，可看到如下界面 点击 Insert metric at cursor ，即可选择监控指标；点击 Graph ，即可让指标以图表方式展示；点击Execute 按钮，即可看到指标图 三、Grafana 安装和配置1、启动 1$ docker run -d --name=grafana -p 3000:3000 grafana/grafana 2、登录 访问 http://localhost:3000/login ，初始账号/密码为：admin/admin 3、配置数据源 点击左侧齿轮Configuration中Add Data Source，会看到如下界面： 这里我们选择Prometheus 当做数据源，这里我们就配置一下Prometheus 的访问地址，点击 Save &amp; Test 4、创建监控 Dashboard 点击导航栏上的 + 按钮，并点击Dashboard，将会看到类似如下的界面 点击+ Add new panel 四、自定义监控指标1、创建 Prometheus 监控管理类PrometheusCustomMonitor 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import io.micrometer.core.instrument.Counter;import io.micrometer.core.instrument.DistributionSummary;import io.micrometer.core.instrument.MeterRegistry;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import java.util.concurrent.atomic.AtomicInteger;@Componentpublic class PrometheusCustomMonitor &#123; private Counter requestErrorCount; private Counter orderCount; private DistributionSummary amountSum; private AtomicInteger failCaseNum; private final MeterRegistry registry; @Autowired public PrometheusCustomMonitor(MeterRegistry registry) &#123; this.registry = registry; &#125; @PostConstruct private void init() &#123; requestErrorCount = registry.counter(\"requests_error_total\", \"status\", \"error\"); orderCount = registry.counter(\"order_request_count\", \"order\", \"test-svc\"); amountSum = registry.summary(\"order_amount_sum\", \"orderAmount\", \"test-svc\"); failCaseNum = registry.gauge(\"fail_case_num\", new AtomicInteger(0)); &#125; public Counter getRequestErrorCount() &#123; return requestErrorCount; &#125; public Counter getOrderCount() &#123; return orderCount; &#125; public DistributionSummary getAmountSum() &#123; return amountSum; &#125; public AtomicInteger getFailCaseNum() &#123; return failCaseNum; &#125;&#125; 2、新增/order接口 当 flag=&quot;1&quot;时，抛异常，模拟下单失败情况。在接口中统计order_request_count和order_amount_sum 12345678910111213141516171819202122232425262728import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import javax.annotation.Resource;import java.util.Random;@RestControllerpublic class TestController &#123; @Resource private PrometheusCustomMonitor monitor; @RequestMapping(\"/order\") public String order(@RequestParam(defaultValue = \"0\") String flag) throws Exception &#123; // 统计下单次数 monitor.getOrderCount().increment(); if (\"1\".equals(flag)) &#123; throw new Exception(\"出错啦\"); &#125; Random random = new Random(); int amount = random.nextInt(100); // 统计金额 monitor.getAmountSum().record(amount); monitor.getFailCaseNum().set(amount); return \"下单成功, 金额: \" + amount; &#125;&#125; 3、新增全局异常处理器GlobalExceptionHandler 统计下单失败次数requests_error_total 123456789101112131415161718import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.ResponseBody;import javax.annotation.Resource;@ControllerAdvicepublic class GlobalExceptionHandler &#123; @Resource private PrometheusCustomMonitor monitor; @ResponseBody @ExceptionHandler(value = Exception.class) public String handle(Exception e) &#123; monitor.getRequestErrorCount().increment(); return \"error, message: \" + e.getMessage(); &#125;&#125; 4、测试 启动项目，访问http://localhost:8080/order和http://localhost:8080/order?flag=1模拟下单成功和失败的情况，然后我们访问http://localhost:8080/actuator/prometheus，可以看到我们自定义指标已经被 /prometheus 端点暴露出来 12345678910# HELP requests_error_total # TYPE requests_error_total counterrequests_error_total&#123;application=&quot;springboot-actuator-prometheus-test&quot;,status=&quot;error&quot;,&#125; 41.0# HELP order_request_count_total # TYPE order_request_count_total counterorder_request_count_total&#123;application=&quot;springboot-actuator-prometheus-test&quot;,order=&quot;test-svc&quot;,&#125; 94.0# HELP order_amount_sum # TYPE order_amount_sum summaryorder_amount_sum_count&#123;application=&quot;springboot-actuator-prometheus-test&quot;,orderAmount=&quot;test-svc&quot;,&#125; 53.0order_amount_sum_sum&#123;application=&quot;springboot-actuator-prometheus-test&quot;,orderAmount=&quot;test-svc&quot;,&#125; 2701.0 5、使用 Prometheus 监控 重新运行 docker 1docker run -d -p 9090:9090 -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml 选择对应指标后可以看到数据变化 6、使用 Grafana 展示 在 Dashboard 界面选择对应的监控指标即可 参考资料： Metric types | Prometheus IntelliJ IDEA创建第一个Spring Boot项目_Study Notes-CSDN博客 Spring Boot 使用 Micrometer 集成 Prometheus 监控 Java 应用性能 【springboot 2.0】 Micrometer Application Monitoring【官方文档】 Spring Boot 微服务应用集成Prometheus + Grafana 实现监控告警 ★ Monitoring Java Spring Boot applications with Prometheus: Part 1 | by Arush Salil | Kubernauts 【放弃这个教程？】client java 不支持 springboot 2.x，最高支持 1.5 Spring Boot 参考指南（端点）_风继续吹 - SegmentFault 思否","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"SpringBoot, Prometheus","slug":"SpringBoot-Prometheus","permalink":"https://simon-ace.github.io/tags/SpringBoot-Prometheus/"}]},{"title":"vim 常用操作","slug":"vim 常用操作","date":"2020-09-16T16:00:00.000Z","updated":"2020-09-17T03:12:52.618Z","comments":true,"path":"2020/09/17/vim 常用操作/","link":"","permalink":"https://simon-ace.github.io/2020/09/17/vim 常用操作/","excerpt":"12# 取消高亮:noh","text":"12# 取消高亮:noh 取消搜索后高亮 1234# no high light search:nohlsearch# 简写:noh","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"vim, 教程","slug":"vim-教程","permalink":"https://simon-ace.github.io/tags/vim-教程/"}]},{"title":"虚拟机 Hadoop 环境配置","slug":"虚拟机Hadoop环境配置","date":"2020-09-16T16:00:00.000Z","updated":"2020-10-08T10:14:34.572Z","comments":true,"path":"2020/09/17/虚拟机Hadoop环境配置/","link":"","permalink":"https://simon-ace.github.io/2020/09/17/虚拟机Hadoop环境配置/","excerpt":"","text":"一、安装 CentOS 6 &amp; 基本配置 win10通过VMware安装CentOS6.5 - 简书https://www.jianshu.com/p/9d5b9757a1ef 1、关闭防火墙 12service iptables stopchkconfig iptables off 2、创建普通用户 12useradd Acepasswd 123 3、创建软件存储文件夹，并更改所有权 12mkdir /opt/software /opt/modulechown Ace:Ace /opt/software /opt/module 4、用户添加到 sudoers 12vi /etc/sudoersAce ALL=(ALL) NOPASSWD:ALL 5、改 Hosts 12345#!/bin/bashfor ((i=101;i&lt;105;i++))do echo \"192.168.87.$i hadoop$i\" &gt;&gt; /etc/hostsdone 6、改静态 ip vim /etc/sysconfig/network-scripts/ifcfg-eth0 123456789DEVICE=eth0TYPE=EthernetONBOOT=yesBOOTPROTO=staticIPADDR=192.168.87.100PREFIX=24GATEWAY=192.168.87.2DNS1=192.168.87.2NAME=\"System eth0\" 【创建新虚拟机，下面的都要做一遍，可以写脚本解决（看下面，推荐）】 6、改 ip 地址（同上6） vim /etc/sysconfig/network-scripts/ifcfg-eth0 1IPADDR=192.168.87.100 # 改成对应的 7、改主机名 vim /etc/sysconfig/network 1HOSTNAME=hadoopxxx 8、删除多余网卡 vim /etc/udev/rules.d/70-persistent-net.rules 12# 第一行删掉（只保留一个网卡就行，注释也删掉，手动删的话记得和后面脚本的行数要对应上）# 第二行最后 NAME=\"eth1\" 改为 NAME=\"eth0\" 9、拍快照，克隆 【脚本】 分发脚本 xsync vim xsync 123456789101112131415161718192021#!/bin/bash# 获取输入参数个数，如果没有参数，直接退出pcount=$#if ((pcount==0)); thenecho no args;exit;fip1=$1fname=`basename $p1`echo fname=$fnamedirname=`cd -P $(dirname $p1); pwd`echo dirname=$dirnameuser=`whoami`for((i=102;i&lt;105;i++)); do echo \"------------- hadoop$i ------------\" rsync -avlP $dirname/$fname hadoop$i:$dirnamedone 移动到bin目录下，sudo mv xsync /bin 安装rsync，sudo yum install -y rsync 改权限，chmod +x xsync 自动配置网络脚本 123456789101112131415161718#!/bin/bashid=$1# sed -i \"s/before replace/after replace/\"sudo sed -i \"s/192.168.87.101/192.168.87.$id/\" /etc/sysconfig/network-scripts/ifcfg-eth0sudo sed -i \"s/hadoop101/hadoop$id/\" /etc/sysconfig/networkfile=/etc/udev/rules.d/70-persistent-net.rules# count \"SUBSYSTEM\" word numbernu=$(grep -c SUBSYSTEM $file)if(($nu &gt; 1));then # delete 8th line sed -i '8d' $filefised -i 's/eth1/eth0/' $filereboot 改权限，chmod +x change_network 二、安装 JAVA 和 Hadoop1、下载/上传 java 和 hadoop 的包到 /opt/software 2、解压 java 和 hadoop 到 /opt/module 3、安装（配置环境变量） 12345678910sudo vim /etc/profile# 在末尾添加# JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin# HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 4、测试安装情况 执行下面命令后，能出现版本号即为成功 12$ java -version$ hadoop version 5、使用 xsync 同步到多个机器上 三、运行配置Apache Hadoop 3.2.1 – Hadoop: Setting up a Single Node Cluster. 安装插件 1234567$ sudo yum install ssh$ sudo yum install pdsh # pdsh 可能默认找不到$ wget http://mirrors.mit.edu/epel/6/i386/epel-release-6-8.noarch.rpm$ rpm -Uvh epel-release-6-8.noarch.rpm$ yum install pdsh 环境配置 vim etc/hadoop/hadoop-env.sh 1export JAVA_HOME=/your-java-home-path 3.1 本地运行模式1234$ mkdir input$ cp etc/hadoop/*.xml input$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output 'dfs[a-z.]+'$ cat output/* 3.2 伪分布式1、配置 vim etc/hadoop/core-site.xml 12345678910111213&lt;configuration&gt; &lt;!-- 指定HDFS中NameNode的地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; etc/hadoop/hdfs-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 暂时不配置 yarn 了 etc/hadoop/yarn-env.sh 1export JAVA_HOME=/opt/module/jdk1.8.0_144 2、设置免密码登录 123$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys$ chmod 0600 ~/.ssh/authorized_keys 3、执行 Format the filesystem: 1$ bin/hdfs namenode -format Start NameNode daemon and DataNode daemon: 1$ sbin/start-dfs.sh The hadoop daemon log output is written to the $HADOOP_LOG_DIR directory (defaults to $HADOOP_HOME/logs). Browse the web interface for the NameNode; by default it is available at: NameNode - http://localhost:9870/ Make the HDFS directories required to execute MapReduce jobs: 12$ bin/hdfs dfs -mkdir /user$ bin/hdfs dfs -mkdir /user/&lt;username&gt; Copy the input files into the distributed filesystem: 12$ bin/hdfs dfs -mkdir input$ bin/hdfs dfs -put etc/hadoop/*.xml input Run some of the examples provided: 1$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output &apos;dfs[a-z.]+&apos; Examine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine them: 12$ bin/hdfs dfs -get output output$ cat output/* or View the output files on the distributed filesystem: 1$ bin/hdfs dfs -cat output/* When you’re done, stop the daemons with: 1$ sbin/stop-dfs.sh 3.3 完全分布式同步两个软件，/etc/profile 3.3.1 集群配置 集群部署规划 NN 1个； 2NN 1个；RM 1个；DN 3个、NM 3个 —— 最少共需六台机器，但是开不起那么多个虚拟机，因此按下表进行合并配置 hadoop102 hadoop103 hadoop104 HDFS NameNode, DataNode DataNode SecondaryNameNode, DataNode YARN NodeManager ResourceManager, NodeManager NodeManager 配置集群 1）核心配置文件 配置etc/hadoop/core-site.xml 1234567891011&lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop102:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;&lt;/property&gt; 2）HDFS配置文件 配置``etc/hadoop/hadoop-env.sh` 1export JAVA_HOME=/opt/module/jdk1.8.0_144 配置etc/hadoop/hdfs-site.xml 12345678910&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;hadoop104:50090&lt;/value&gt;&lt;/property&gt; 3）YARN配置文件 配置etc/hadoop/yarn-env.sh 1export JAVA_HOME=/opt/module/jdk1.8.0_144 配置etc/hadoop/yarn-site.xml 1234567891011&lt;!-- Reducer获取数据的方式 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定YARN的ResourceManager的地址 --&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop103&lt;/value&gt;&lt;/property&gt; 4）MapReduce配置文件 配置etc/hadoop/mapred-env.sh 1export JAVA_HOME=/opt/module/jdk1.8.0_144 配置etc/hadoop/mapred-site.xml 12345678910$ cp mapred-site.xml.template mapred-site.xml~~&lt;!-- 指定MR运行在Yarn上 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;~~ 在集群上分发配置好的Hadoop配置文件 1$ xsync /opt/module/hadoop-2.7.2/ 3.3.2 集群单点启动1）如果集群是第一次启动，需要格式化NameNode 1$ hadoop namenode -format 2）在 hadoop102 上启动 NameNode 1$ hadoop-daemon.sh start namenode 3）在 hadoop102、hadoop103、hadoop104 上分别启动DataNode 1$ hadoop-daemon.sh start datanode 4）在 hadoop104 上启动 secondarynamenode 1$ hadoop-daemon.sh start secondarynamenode 5）查看服务启动情况 jps 12345678910111213[hadoop102]$ jps4182 Jps2842 DataNode2747 NameNode[hadoop103]$ jps1712 DataNode2215 Jps[hadoop104]$ jps1680 DataNode2266 Jps2171 SecondaryNameNode 3.3.3 集群一键启动 配置机器间 ssh 无密登录 「方法1：共用一个秘钥」 123456# 生成秘钥$ ssh-keygen -t rsa# 将秘钥添加到本机的 authorized_keys 中，实现本机无密登录$ ssh-copy-id hadoop102# 共享同一个秘钥，实现集群机器间无密登录$ xsync ~/.ssh 「方法2：每个机器单独生成秘钥」 123456# 在每个机器上生成秘钥（每个机器执行一遍）$ ssh-keygen -t rsa# 把每个机器的秘钥分发到别的机器上（每个机器执行一遍）$ ssh-copy-id hadoop102$ ssh-copy-id hadoop103$ ssh-copy-id hadoop104 添加机器名，配置etc/hadoop/slaves，并同步到其他机器（xsync） 123hadoop102hadoop103hadoop104 启动 12[hadoop102]$ start-dfs.sh[hadoop103]$ start-yarn.sh # 应该在ResouceManager所在的机器上启动YARN 测试（单词计数） 1234567891011121314151617181920212223# 创建一个文件夹 wcinput，里面放一个文件，添加计数文件中的内容，如：qwedddsmo123qwe# 将这个文件夹上传到 hdfs$ hadoop fs -put wcinput/ /# 执行 MapReduce 程序$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /wcinput /output# 查看执行结果[Ace@hadoop102 hadoop-2.7.2]$ hadoop fs -ls /outputFound 2 items-rw-r--r-- 3 Ace supergroup 0 2020-09-27 10:15 /output/_SUCCESS-rw-r--r-- 3 Ace supergroup 24 2020-09-27 10:15 /output/part-r-00000[Ace@hadoop102 hadoop-2.7.2]$ hadoop fs -cat /output/part-r-00000123 1ddd 1qwe 2smo 1 停止 12[hadoop102]$ stop-dfs.sh[hadoop103]$ stop-yarn.sh 3.3.4 配置历史服务器 &amp; 日志聚集 配置etc/hadoop/mapred-site.xml，添加： 12345678910&lt;!-- 历史服务器端地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop104:10020&lt;/value&gt;&lt;/property&gt;&lt;!-- 历史服务器web端地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop104:19888&lt;/value&gt;&lt;/property&gt; 配置etc/hadoop/yarn-site.xml 12345678910&lt;!-- 日志聚集功能使能 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 日志保留时间设置7天 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt;&lt;/property&gt; [分发配置] 启动 1234[hadoop102]$ start-dfs.sh[hadoop103]$ start-yarn.sh[hadoop104]$ mr-jobhistory-daemon.sh start historyserver$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /wcinput /output1 查看 打开 yarn web http://hadoop103:8088/ 打开 history，在点 log 就能看到任务具体的日志信息了 ![image-20201008173041985](../../../../../Library/Application Support/typora-user-images/image-20201008173041985.png) 3.3.5 集群时间同步1）检查 ntp 是否安装 查看 ntp 包（切换到 root 用户） 123[root@hadoop102 ~]# rpm -qa | grep ntpntp-4.2.6p5-15.el6.centos.x86_64ntpdate-4.2.6p5-15.el6.centos.x86_64 如果没有这两个服务要安装一下 1yum install -y ntp 先停止 ntp 服务 1234567# 查看 ntpd 服务是否在运行$ service ntpd status# 如果在运行先关闭$ service ntpd stop$ chkconfig ntpd off# 再查看一下 ntpd 运行情况$ chkconfig --list ntpd 2）修改ntp配置文件/etc/ntp.conf 123456789101112# 修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap# 修改2（集群在局域网中，不使用其他互联网上的时间），将下面四行注释掉server 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst# 添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）server 127.127.1.0fudge 127.127.1.0 stratum 10 3）修改/etc/sysconfig/ntpd文件 12增加内容如下（让硬件时间与系统时间一起同步）SYNC_HWCLOCK=yes 4）重新启动ntpd服务 12$ service ntpd status$ service ntpd start 5）设置ntpd服务开机启动 1[hadoop102]$ chkconfig ntpd on 6）其他机器配置（必须root用户） 在其他机器配置10分钟与时间服务器同步一次 12$ crontab -e*/10 * * * * /usr/sbin/ntpdate hadoop102 测试（修改任意机器时间），十分钟后查看机器是否与时间服务器同步 1$ date -s \"2017-9-11 11:11:11\" 7）若主机时间不对 123$ service ntpd stop$ ntpdate us.pool.ntp.org$ service ntpd start","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"Hadoop, 教程","slug":"Hadoop-教程","permalink":"https://simon-ace.github.io/tags/Hadoop-教程/"}]},{"title":"Linux压缩命令","slug":"Linux压缩命令","date":"2020-08-31T16:00:00.000Z","updated":"2020-09-01T02:41:59.205Z","comments":true,"path":"2020/09/01/Linux压缩命令/","link":"","permalink":"https://simon-ace.github.io/2020/09/01/Linux压缩命令/","excerpt":"12345678# 解压 tar包tar -xvf file.tar # 解压tar.gztar -xzvf file.tar.gz # 1.15版本后 tar 自动识别压缩方式tar -xvf filename.tar.gz","text":"12345678# 解压 tar包tar -xvf file.tar # 解压tar.gztar -xzvf file.tar.gz # 1.15版本后 tar 自动识别压缩方式tar -xvf filename.tar.gz 一、常用压缩参数必选参数，压缩解压都要用到其中一个： -c: 建立压缩档案 -x：解压 -t：查看内容 -r：向压缩归档文件末尾追加文件 -u：更新原压缩包中的文件 可选参数： -z：有gzip属性的 -j： 有bz2属性的 -Z：有compress属性的 -v：显示所有过程 -O：将文件解开到标准输出 下面的参数-f是必须的 -f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。 二、举个栗子压缩 1234567891011# 将目录里所有jpg文件打包成tar.jpgtar -cvf jpg.tar *.jpg # 将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gztar -czf jpg.tar.gz *.jpg # rar格式的压缩，需要先下载rar for linuxrar a jpg.rar *.jpg # zip格式的压缩，需要先下载zip for linuxzip jpg.zip *.jpg 解压 1234567891011121314# 解压 tar包tar -xvf file.tar # 解压tar.gztar -xzvf file.tar.gz # 解压 tar.bz2tar -xjvf file.tar.bz2 # 解压rarunrar e file.rar # 解压zipunzip file.zip 从1.15版本开始tar就可以自动识别压缩的格式,故不需人为区分压缩格式就能正确解压 1234tar -xvf filename.tar.gztar -xvf filename.tar.bz2tar -xvf filename.tar.xztar -xvf filename.tar.Z","categories":[{"name":"技术","slug":"技术","permalink":"https://simon-ace.github.io/categories/技术/"}],"tags":[{"name":"Linux, 压缩","slug":"Linux-压缩","permalink":"https://simon-ace.github.io/tags/Linux-压缩/"}]},{"title":"构建Hadoop的Docker编译环境","slug":"构建 Hadoop 的 Docker 编译环境","date":"2020-08-31T16:00:00.000Z","updated":"2020-09-02T02:47:19.693Z","comments":true,"path":"2020/09/01/构建 Hadoop 的 Docker 编译环境/","link":"","permalink":"https://simon-ace.github.io/2020/09/01/构建 Hadoop 的 Docker 编译环境/","excerpt":"","text":"一、配置 docker 环境 参考链接：Hadoop安装之一：使用Docker编译64位的Hadoop - 简书 1. 制作 CentOS 7 基础镜像（可选）Docker Hub上已经提供了CentOS7的官方镜像，但并未激活 Systemd（用来启动守护进程），制作一个启动 Systemd 的镜像。（这里编译Hadoop其实用不到systemd） Dockerfile 1234567891011121314151617181920212223242526# 镜像来源FROM centos:7# 镜像创建者MAINTAINER \"you\" &lt;your@email.here&gt;# 设置一个环境变量ENV container docker# 运行命令# 设置systemdRUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == \\systemd-tmpfiles-setup.service ] || rm -f $i; done); \\rm -f /lib/systemd/system/multi-user.target.wants/*;\\rm -f /etc/systemd/system/*.wants/*;\\rm -f /lib/systemd/system/local-fs.target.wants/*; \\rm -f /lib/systemd/system/sockets.target.wants/*udev*; \\rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \\rm -f /lib/systemd/system/basic.target.wants/*;\\rm -f /lib/systemd/system/anaconda.target.wants/*;# 挂载一个本地文件夹VOLUME [ \"/sys/fs/cgroup\" ]# 设置容器启动时的执行命令CMD [\"/usr/sbin/init\"] 生成镜像 1docker build -t centos7-systemd . 2. 安装 Oracle Java 参考链接使用yum卸载、安装jdk_不做小白的博客-CSDN博客 注意不要使用 openjdk，会导致编译 hive 时出现问题 启动刚刚生成的镜像 从官网下载 oracle java jdk-8u202-linux-x64.tar.gz 安装 Java，配置环境变量 12345678910111213141516171819mkdir /usr/local/javacp jdk-8u202-linux-x64.tar.gz /usr/local/javacd /usr/local/javatar -xzvf jdk-8u202-linux-x64.tar.gz# 配置环境变量vim /etc/profile~~export JAVA_HOME=/usr/local/java/jdk1.8.0_202export JRE_HOME=/usr/local/java/jdk1.8.0_202/jre export PATH=$PATH:/usr/local/java/jdk1.8.0_202/bin export CLASSPATH=./:/usr/local/java/jdk1.8.0_202/lib:/usr/local/java/jdk1.8.0_202/jre/lib~~source /etc/profile# 检查 JAVA 是否安装成功java -version 保存镜像 1docker commit 容器id 镜像名 3. 制作编译镜像 编译脚本 1234567891011121314151617181920$ vi compile.sh#!/bin/bash# 设置默认编译版本(支持传参)version=$&#123;1:-2.7.3&#125;# 进入源代码目录cd /hadoop-$version-src# 开始编译echo -e \"\\n\\ncompile hadoop $version...\"mvn clean package -Pdist,native -DskipTests -Dtar# 输出结果if [[ $? -eq 0]]; then echo -e \"\\n\\ncompile hadoop $version success!\\n\\n\"else echo -e \"\\n\\ncompile hadoop $version fail!\\n\\n\"fi Dockerfile（其中有不少安装包不是必要的） 123456789101112131415161718192021222324252627# 镜像来源(第二步生成的本地镜像)FROM centos7-systemd-java# 镜像创建者MAINTAINER \"you\" &lt;your@email.here&gt;# 运行命令安装环境依赖# 使用 -y 同意全部询问RUN yum update -y &amp;&amp; \\ yum groupinstall -y \"Development Tools\" &amp;&amp; \\ yum install -y wget \\ protobuf-devel \\ protobuf-compiler \\ maven \\ cmake \\ pkgconfig \\ openssl-devel \\ zlib-devel \\ gcc \\ automake \\ autoconf \\ make # 复制编辑脚本文件到镜像中COPY compile.sh /root/compile.sh# 设置脚本文件的可运行权限RUN chmod +x /root/compile.sh 生成镜像 1sudo docker build -t centos7-hadoop-compiler . 二、编译源码 hive（大概10分钟） 1mvn clean package -Pdist -DskipTests hadoop（大概15分钟） 1mvn clean package -Pdist,native -DskipTests -Dtar 也可以使用 docker image 中的脚本编译 12$ export VERSION=2.7.3$ sudo docker run -v $(pwd)/hadoop-$VERSION-src:/hadoop-$VERSION-src --privileged=true centos7-hadoop-complier /root/compile.sh $VERSION 要添加 privileged 参数！ [docker]privileged参数_追寻神迹-CSDN博客 使用该参数，container内的root拥有真正的root权限。否则，container内的root只是外部的一个普通用户权限。 总结 1234567891011121314151617181920212223242526272829# pull docker imagedocker pull shuofxz/hadoop-compiler:1.0# === HADOOP ===# hadoop download link# new versionhttps://hadoop.apache.org/releases.html# old versionhttps://archive.apache.org/dist/hadoop/common/# compile command (about 15 minutes to complete)mvn package -Pdist,native -DskipTests -Dtar# compile with script file$ export VERSION=2.7.3$ sudo docker run -v $(pwd)/hadoop-$VERSION-src:/hadoop-$VERSION-src --privileged=true shuofxz/hadoop-compiler:1.0 /root/hadoop-compile.sh $VERSION# === HIVE ===# hive download link# select corresponding branch src file to downloadhttps://github.com/apache/hive# compile command (about 10 minutes to complete)mvn clean package -Pdist -DskipTests# compile with script file$ export VERSION=2.3.0$ sudo docker run -v $(pwd)/hive-rel-release-$VERSION:/hive-rel-release-$VERSION --privileged=true shuofxz/hadoop-compiler:1.0 /root/hive-compile.sh $VERSION hadoop-2.7.0-src.tar.gz release-2.3.0.tar.gz 已包括各种库的 image，可以直接编译 hadoop（不好用） GitHub - kiwenlau/compile-hadoop: Compile Hadoop in Docker containerhttps://github.com/kiwenlau/compile-hadoop","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"docker,教程","slug":"docker-教程","permalink":"https://simon-ace.github.io/tags/docker-教程/"}]},{"title":"Docker 批量操作","slug":"Docker 批量操作","date":"2020-08-27T16:00:00.000Z","updated":"2020-09-01T10:04:59.753Z","comments":true,"path":"2020/08/28/Docker 批量操作/","link":"","permalink":"https://simon-ace.github.io/2020/08/28/Docker 批量操作/","excerpt":"1docker rmi $(docker images | grep \"none\" | awk '&#123;print $3&#125;')","text":"1docker rmi $(docker images | grep \"none\" | awk '&#123;print $3&#125;') 列出所有的容器 ID 1docker ps -aq 停止所有的容器 1docker stop $(docker ps -aq) 删除所有的容器 1docker rm $(docker ps -aq) 删除所有的镜像 1docker rmi $(docker images -q) 删除指定名称镜像 1docker rmi $(docker images | grep \"none\" | awk '&#123;print $3&#125;') 复制文件 12docker cp mycontainer:/opt/file.txt /opt/local/docker cp /opt/local/file.txt mycontainer:/opt/ 现在的docker有了专门清理资源(container、image、网络)的命令。 docker 1.13 中增加了 docker system prune的命令，针对container、image可以使用docker container prune、docker image prune命令。 删除所有不使用的镜像 123docker image prune --force --all# ordocker image prune -f -a 删除所有停止的容器 1docker container prune -f","categories":[{"name":"技术","slug":"技术","permalink":"https://simon-ace.github.io/categories/技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://simon-ace.github.io/tags/docker/"}]},{"title":"Cron语法","slug":"cron语法","date":"2020-08-16T16:00:00.000Z","updated":"2020-08-17T10:33:34.460Z","comments":true,"path":"2020/08/17/cron语法/","link":"","permalink":"https://simon-ace.github.io/2020/08/17/cron语法/","excerpt":"12* * * * * * *秒 分钟 小时 天 月 星期 年","text":"12* * * * * * *秒 分钟 小时 天 月 星期 年 1 表达式详解一个cron表达式有至少6个（也可能7个）有空格分隔的时间元素。 按顺序依次为 1 秒（0~59） 2 分钟（0~59） 3 小时（0~23） 4 天（0~31） 5 月（0~11） 6 星期（1~7 1=SUN 或 SUN，MON，TUE，WED，THU，FRI，SAT） 7 年份（1970－2099） 每个元素格式： 一个具体值（如6） 一个连续区间（9-12） 一个列表(1,3,5) 特殊字符 通配符（*），所有可能的值 空符号（？），表示不指定值 由于”月份中的日期”和”星期中的日期”这两个元素互斥的,必须要对其中一个设置? 增量符（/） 如第二位12/10 表示从第12分钟开始，每10分钟（它和“12，22，32…”） 最后（L） 仅被用于天（月）和天（星期）两个子表达式，它是单词“last”的缩写 “6L”表示这个月的倒数第６天 平日（W） 仅能用于日域中，它用来指定离指定日的最近的一个工作日（1-5） 日域中的 15W 意味着 “离该月15号的最近一个平日 2 例子123456789101112130 0 10,14,16 * * ? 每天上午10点，下午2点，4点0 0/30 9-17 * * ? 朝九晚五工作时间内每半小时0 0 12 ? * WED 表示每个星期三中午12点0 0 12 * * ? 每天中午12点触发0 15 10 ? * * 每天上午10:15触发0 15 10 * * ? 2005 2005年的每天上午10:15触发0 * 14 * * ? 在每天下午2点到下午2:59期间的每1分钟触发0 0/5 14,18 * * ? 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发0 0-5 14 * * ? 在每天下午2点到下午2:05期间的每1分钟触发0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发0 15 10 ? * MON-FRI 周一至周五的上午10:15触发0 15 10 L * ? 每月最后一日的上午10:15触发0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发","categories":[{"name":"技术","slug":"技术","permalink":"https://simon-ace.github.io/categories/技术/"}],"tags":[{"name":"cron","slug":"cron","permalink":"https://simon-ace.github.io/tags/cron/"}]},{"title":"Hexo常用命令","slug":"Hexo常用命令","date":"2020-08-12T16:00:00.000Z","updated":"2020-08-13T10:18:27.861Z","comments":true,"path":"2020/08/13/Hexo常用命令/","link":"","permalink":"https://simon-ace.github.io/2020/08/13/Hexo常用命令/","excerpt":"123456# 生成静态文件hexo g# 启动服务hexo s# 部署hexo d","text":"123456# 生成静态文件hexo g# 启动服务hexo s# 部署hexo d 常用命令 生成静态文件 123hexo generate# 简写hexo g 启动服务预览文章 12345hexo server# 简写hexo s# 指定端口hexo server -p 5000 一键部署 123hexo deploy# 简写hexo d","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://simon-ace.github.io/tags/Hexo/"}]},{"title":"","slug":"Docker部署Vue项目","date":"2020-08-12T07:02:40.098Z","updated":"2020-08-12T07:02:43.859Z","comments":true,"path":"2020/08/12/Docker部署Vue项目/","link":"","permalink":"https://simon-ace.github.io/2020/08/12/Docker部署Vue项目/","excerpt":"","text":"[手把手系列之]Docker 部署 vue 项目 - 掘金https://juejin.im/post/6844903837774397447","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2020-07-10T03:23:10.782Z","updated":"2020-07-10T03:23:10.782Z","comments":true,"path":"2020/07/10/hello-world/","link":"","permalink":"https://simon-ace.github.io/2020/07/10/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Mac安装node","slug":"Mac安装node","date":"2020-07-09T16:00:00.000Z","updated":"2020-07-10T06:24:18.048Z","comments":true,"path":"2020/07/10/Mac安装node/","link":"","permalink":"https://simon-ace.github.io/2020/07/10/Mac安装node/","excerpt":"Mac安装及降级node版本","text":"Mac安装及降级node版本 1 安装最新版Node 安装HomeBrew 1/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" 安装Node 1brew install node 验证Node是否安装成功 输入下面两条指令看是否可以都输出版本号 12node -vnpm -v 2 降级Node由于开发需要或版本兼容性，需要安装低版本的Node，按下面的方式操作 卸载Node 如果你是按前面的方法安装的Node，则用下面的命令卸载 1brew uninstall node 查看可用的Node版本 1brew search node 输出结果： 12==&gt; Formulaelibbitcoin-node node node-sass node@12 nodebrew nodenv llnode node-build node@10 node_exporter nodeenv 安装你需要的版本 12# 这里安装v12版本brew install node@12 连接Node 12brew link node@12# 这一步可能会报错, 按照提示执行命令就ok了, 比如我最后执行的是brew link --overwrite --force node@12 检查Node是否安装成功 1node -v","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/tags/教程/"}]},{"title":"Mac使用代理ssh远程连接服务器","slug":"Mac使用代理ssh远程连接服务器","date":"2020-07-09T16:00:00.000Z","updated":"2020-07-10T11:51:05.513Z","comments":true,"path":"2020/07/10/Mac使用代理ssh远程连接服务器/","link":"","permalink":"https://simon-ace.github.io/2020/07/10/Mac使用代理ssh远程连接服务器/","excerpt":"123456# 直接连接ssh -p 端口号 服务器用户名@ip地址# eg: ssh -p 22 userkunyu@119.29.37.63# 通过代理连接ssh -o ProxyCommand=\"nc -X 5 -x 代理服务器ip:代理服务器端口 %h %p\" 需要访问的服务器的用户名@需要访问的服务器ip","text":"123456# 直接连接ssh -p 端口号 服务器用户名@ip地址# eg: ssh -p 22 userkunyu@119.29.37.63# 通过代理连接ssh -o ProxyCommand=\"nc -X 5 -x 代理服务器ip:代理服务器端口 %h %p\" 需要访问的服务器的用户名@需要访问的服务器ip 1 直接连接12# ssh -p 端口号 服务器用户名@ip地址ssh -p 22 userkunyu@119.29.37.63 2 通过代理连接 直接连接 12# ssh -o ProxyCommand=\"nc -X 5 -x 代理服务器ip:代理服务器端口 %h %p\" 需要访问的服务器的用户名@需要访问的服务器ipssh -o ProxyCommand=\"nc -X 5 -x 192.168.0.255:9999 %h %p\" user_name@192.168.77.200 使用SSH配置文件 1sudo vi ~/.ssh/config 12Host * ProxyCommand nc -X 5 -x 192.168.0.255:9999 %h %p 配置好了之后就可以和直接连接一样使用 1ssh uesr@ip Mac下SSH跳点连接及代理连接_Dawnworld-CSDN博客_mac ssh 代理https://blog.csdn.net/thundon/article/details/46858957","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/tags/教程/"}]},{"title":"iTerm2配置","slug":"iTerm2配置","date":"2020-07-09T16:00:00.000Z","updated":"2020-07-10T10:23:28.607Z","comments":true,"path":"2020/07/10/iTerm2配置/","link":"","permalink":"https://simon-ace.github.io/2020/07/10/iTerm2配置/","excerpt":"iTerm2配置 Oh-my-zsh安装，主题配置","text":"iTerm2配置 Oh-my-zsh安装，主题配置 1 安装iTerm2iTerm2 是一款完全免费的，专为 Mac OS 用户打造的命令行应用。直接在官网上 http://iterm2.com/ 下载并安装即可。 设置为默认终端 2 安装 oh-my-zshbash是mac中terminal自带的shell，把它换成oh-my-zsh，这个的功能要多得多。拥有语法高亮，命令行tab补全，自动提示符，显示Git仓库状态等功能。 1sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" 解决权限问题 如果安装完重启iterm之后，出现下面的提示： 12345[oh-my-zsh] Insecure completion-dependent directories detected:drwxrwxrwx 7 hans admin 238 2 9 10:13 /usr/local/share/zshdrwxrwxrwx 6 hans admin 204 10 1 2017 /usr/local/share/zsh/site-functions...... 解决方法： 12chmod 755 /usr/local/share/zshchmod 755 /usr/local/share/zsh/site-functions 3 配置主题4 Vim配置设置鼠标滚动","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/tags/教程/"}]},{"title":"Linux后台执行命令","slug":"Linux后台执行命令","date":"2019-10-21T16:00:00.000Z","updated":"2020-07-10T03:23:10.779Z","comments":true,"path":"2019/10/22/Linux后台执行命令/","link":"","permalink":"https://simon-ace.github.io/2019/10/22/Linux后台执行命令/","excerpt":"当在终端工作时，可能一个持续运行的作业占住屏幕输出，或终端退出时导致命令结束。为了避免这些问题，可以将这些进程放到后台运行，且不受终端关闭的影响，可使用下面的方法： 1nohup command &gt; myout.file 2&gt;&amp;1 &amp;","text":"当在终端工作时，可能一个持续运行的作业占住屏幕输出，或终端退出时导致命令结束。为了避免这些问题，可以将这些进程放到后台运行，且不受终端关闭的影响，可使用下面的方法： 1nohup command &gt; myout.file 2&gt;&amp;1 &amp; 1 后台执行命令1.1 命令&amp;在命令后面加上&amp;实现后台运行（控制台关掉(退出帐户时)，作业就会停止运行） 1command &amp; 例：python run.py &amp; 1.2 命令nohupnohup命令可以在你退出帐户之后继续运行相应的进程。nohup就是不挂起的意思( no hang up) 1nohup command &amp; 例：nohup run.py &amp; 2 kill进程执行后台任务命令后，会返回一个进程号，可通过这个进程号kill掉进程。 1kill -9 进程号 3 输出重定向由于使用前面的命令将任务放到后台运行，因此任务的输出也不打印到屏幕上了，所以需要将输出重定向到文件中，以方便查看输出内容。 将输出重定向到 file（覆盖） 1command1 &gt; file1 将输出重定向到 file（追加） 1command1 &gt;&gt; file1 将 stdout 和 stderr 合并后重定向到 file 2&gt;1代表什么，2与&gt;结合代表错误重定向，而1则代表错误重定向到一个文件1，而不代表标准输出；换成2&gt;&amp;1，&amp;与1结合就代表标准输出了，就变成错误重定向到标准输出. 1command1 &gt; file1 2&gt;&amp;1 完整写法： 1nohup command &gt;out.file 2&gt;&amp;1 &amp; 4 其他 nohup执行python程序时，print无法输出 这是因为python的输出有缓冲，导致nohup.out并不能够马上看到输出 python 有个-u参数，使得python不启用缓冲 nohup python -u test.py &gt; nohup.out 2&gt;&amp;1 &amp;","categories":[{"name":"Linux","slug":"Linux","permalink":"https://simon-ace.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://simon-ace.github.io/tags/Linux/"}]},{"title":"Linux统计文件夹下的文件数目","slug":"Linux统计文件夹下的文件数目","date":"2019-10-21T16:00:00.000Z","updated":"2020-07-10T03:23:10.780Z","comments":true,"path":"2019/10/22/Linux统计文件夹下的文件数目/","link":"","permalink":"https://simon-ace.github.io/2019/10/22/Linux统计文件夹下的文件数目/","excerpt":"1$ ls -l | grep &quot;^-&quot; | wc -l","text":"1$ ls -l | grep &quot;^-&quot; | wc -l 1 统计文件夹下的文件数目 统计当前目录下文件的个数（不包括目录） 1$ ls -l | grep &quot;^-&quot; | wc -l 统计当前目录下文件的个数（包括子目录） 1$ ls -lR| grep &quot;^-&quot; | wc -l 查看某目录下文件夹(目录)的个数（包括子目录） 1$ ls -lR | grep &quot;^d&quot; | wc -l 命令原理： ls -l 详细输出该文件夹下文件信息 ls -lR是列出所有文件，包括子目录 grep &quot;^-&quot; 过滤ls的输出信息，只保留一般文件；只保留目录是grep &quot;^d&quot; wc -l 统计输出信息的行数","categories":[{"name":"Linux","slug":"Linux","permalink":"https://simon-ace.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://simon-ace.github.io/tags/Linux/"}]},{"title":"Python打印更详细的异常信息","slug":"Python打印更详细的异常信息","date":"2019-10-20T16:00:00.000Z","updated":"2020-07-10T03:23:10.782Z","comments":true,"path":"2019/10/21/Python打印更详细的异常信息/","link":"","permalink":"https://simon-ace.github.io/2019/10/21/Python打印更详细的异常信息/","excerpt":"打印Python异常信息的几种方式","text":"打印Python异常信息的几种方式 1 简单的异常信息1234try: a = 1/0except Exception as e: print(e) 打印最简单的message信息： 1division by zero 2 更完整的信息12345678910import tracebacktry: a = 1/0except Exception as e: print('str(e):\\t', e) print('repr(e):\\t', repr(e)) print('traceback.format_exc():\\n%s' % traceback.format_exc()) #字符串 traceback.print_exc() #执行函数 输出： 123456789101112str(e): division by zerorepr(e): ZeroDivisionError(&apos;division by zero&apos;)traceback.format_exc():Traceback (most recent call last): File &quot;/Users/ace/Play/test/异常信息.py&quot;, line 4, in &lt;module&gt; a = 1/0ZeroDivisionError: division by zeroTraceback (most recent call last): File &quot;/Users/ace/Play/test/异常信息.py&quot;, line 4, in &lt;module&gt; a = 1/0ZeroDivisionError: division by zero traceback.format_exc()和traceback.print_exc()都可以打印完整的错误信息 traceback.format_exc()返回值为字符串 traceback.print_exc()是一个执行函数，直接在控制台打印错误信息","categories":[{"name":"Python","slug":"Python","permalink":"https://simon-ace.github.io/categories/Python/"}],"tags":[{"name":"Python, 异常","slug":"Python-异常","permalink":"https://simon-ace.github.io/tags/Python-异常/"}]},{"title":"【转】持续集成 Continuous Integration","slug":"持续集成 Continuous Integration","date":"2019-10-17T16:00:00.000Z","updated":"2020-07-10T03:23:10.782Z","comments":true,"path":"2019/10/18/持续集成 Continuous Integration/","link":"","permalink":"https://simon-ace.github.io/2019/10/18/持续集成 Continuous Integration/","excerpt":"持续集成 Continuous Integration","text":"持续集成 Continuous Integration","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://simon-ace.github.io/tags/Hexo/"}]},{"title":"Hexo多台电脑同步","slug":"Hexo多台电脑同步","date":"2019-10-15T16:00:00.000Z","updated":"2020-08-13T09:06:57.490Z","comments":true,"path":"2019/10/16/Hexo多台电脑同步/","link":"","permalink":"https://simon-ace.github.io/2019/10/16/Hexo多台电脑同步/","excerpt":"如果换了电脑该如何同步Hexo的源文件？把hexo文件从一个电脑cope到另外一个电脑吗？答案肯定不是这样的，因为这里面有好多依赖包，好几万个文件呢，这样显然不合理。 本文提供一种多台电脑同步源文件的方法。","text":"如果换了电脑该如何同步Hexo的源文件？把hexo文件从一个电脑cope到另外一个电脑吗？答案肯定不是这样的，因为这里面有好多依赖包，好几万个文件呢，这样显然不合理。 本文提供一种多台电脑同步源文件的方法。 0 解决思路使用GitHub的分支！在博客对应的仓库中新建一个分支。一个分支用来存放Hexo生成的网站原始的文件，另一个分支用来存放生成的静态网页。 1 创建分支1.1 创建新分支命令行操作： GitHub操作： 点击branch按钮，输入新的分支名source，点创建。 1.2 设置默认分支准备在source分支中存放源文件，master中存放生成的网页，因此将source设置为默认分支，方便同步文件。 在仓库-&gt;Settings-&gt;Branches-&gt;Default branch中将默认分支设为source，save保存 2 源文件上传到GitHub 选好一个本地文件夹，执行 git clone git@github.com:Simon-Ace/Simon-Ace.github.io.git(替换成你的仓库) 在克隆到本地的Simon-Ace.github.io中，把除了.git 文件夹外的所有文件都删掉 把之前我们写的博客源文件全部复制过来，除了.deploy_git 复制过来的源文件应该有一个.gitignore，用来忽略一些不需要的文件，如果没有的话，自己新建一个，在里面写上如下，表示这些类型文件不需要git： 1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 注意，如果你之前克隆过theme中的主题文件，那么应该把主题文件中的.git文件夹删掉，因为git不能嵌套上传。 提交更改 123git add .git commit –m \"add branch\"git push 参考文章： https://juejin.im/post/5acf22e6f265da23994eeac9 https://www.zhihu.com/question/21193762","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://simon-ace.github.io/tags/Hexo/"}]},{"title":"Python-加快pip安装速度","slug":"tutorials/Python-加快pip安装速度","date":"2019-10-15T16:00:00.000Z","updated":"2020-07-10T03:23:10.782Z","comments":true,"path":"2019/10/16/tutorials/Python-加快pip安装速度/","link":"","permalink":"https://simon-ace.github.io/2019/10/16/tutorials/Python-加快pip安装速度/","excerpt":"PIP安装时使用国内镜像，加快下载速度","text":"PIP安装时使用国内镜像，加快下载速度 0 国内源清华：https://pypi.tuna.tsinghua.edu.cn/simple 阿里云：http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 华中理工大学：http://pypi.hustunique.com/ 山东理工大学：http://pypi.sdutlinux.org/ 豆瓣：http://pypi.douban.com/simple/ 1 临时使用 可以在使用pip的时候加参数-i https://pypi.tuna.tsinghua.edu.cn/simple 例如： pip install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy 2 永久修改这样就不用每次都添加国内镜像源地址了 Linux下，修改~/.pip/pip.conf（没有就创建一个文件夹及文件） 打开文件，添加内容： 1234[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host=mirrors.aliyun.com windows下，直接在user目录中创建一个pip目录，如：C:\\Users\\xx\\pip，新建文件pip.ini， 内容同上","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://simon-ace.github.io/tags/Hexo/"}]},{"title":"一台电脑配置多个git账号","slug":"配置多个git账号","date":"2019-10-13T16:00:00.000Z","updated":"2020-07-10T03:28:22.702Z","comments":true,"path":"2019/10/14/配置多个git账号/","link":"","permalink":"https://simon-ace.github.io/2019/10/14/配置多个git账号/","excerpt":"1 清除git全局设置如果配置第一个账号的时候使用git config --global设置过，就先要取消掉，否则两个账号肯定会冲突 123# 取消globalgit config --global --unset user.namegit config --global --unset user.email","text":"1 清除git全局设置如果配置第一个账号的时候使用git config --global设置过，就先要取消掉，否则两个账号肯定会冲突 123# 取消globalgit config --global --unset user.namegit config --global --unset user.email 2 生成新账号的SSH keys2.1 用 ssh-keygen 命令生成密钥1$ ssh-keygen -t rsa -C \"new email\" 平时都是直接回车，默认生成 id_rsa 和 id_rsa.pub。这里特别需要注意，出现提示输入文件名的时候(Enter file in which to save the key (~/.ssh/id_rsa): id_rsa_new)要输入与默认配置不一样的文件名，比如：我这里填的是 id_rsa和id_rsa_me。 如果之前没配置过ssh key，这里用不同邮箱生成两遍即可，注意用不同的文件名 成功后会出现： 12Your identification has been saved in xxx.Your public key has been saved in xxx. 2.2 添加到ssh-agent中使用ssh-add将 IdentityFile 添加到 ssh-agent中 12ssh-add ~/.ssh/id_rsassh-add ~/.ssh/id_rsa_me 2.3 配置 ~/.ssh/config 文件在~/.ssh/下新建config文件 1234567891011# The git info for companyHost git.XXX.com # git别名，写公司的git名字即可HostName git.XXX.com # git名字，同样写公司的git名字User git # 写 git 即可IdentityFile ~/.ssh/id_rsa #私钥路径，若写错会连接失败# The git info for github Host github.com # git别名，写github的git名字即可HostName github.com # git名字，同样写github的git名字User git # 写 git 即可IdentityFile ~/.ssh/id_rsa_me #私钥路径，若写错会连接失败 3 与GitHub链接复制刚刚生成的两个ssh公钥到对应的账号中 文件id_rsa.pub中保存的就是 ssh 公钥 12pbcopy &lt; ~/.ssh/id_rsa.pubpbcopy &lt; ~/.ssh/id_rsa_me.pub 在 github 网站中添加该 ssh 公钥 验证是否配置成功，以 github 为例，输入 ssh -T git@github.com，若出现 1Hi xxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 这样的字段，即说明配置成功。另一个同理。 参考链接： 配置多个git账号的ssh密钥 - 掘金https://juejin.im/post/5befe84d51882557795cc8f9 同一台电脑配置多个git账号 · Issue #2 · jawil/noteshttps://github.com/jawil/notes/issues/2","categories":[{"name":"教程","slug":"教程","permalink":"https://simon-ace.github.io/categories/教程/"}],"tags":[{"name":"git","slug":"git","permalink":"https://simon-ace.github.io/tags/git/"}]}]}