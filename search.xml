<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Shell 编程</title>
      <link href="/2020/11/19/Linux/Shell%20%E7%BC%96%E7%A8%8B/"/>
      <url>/2020/11/19/Linux/Shell%20%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="0-基础"><a href="#0-基础" class="headerlink" title="0 基础"></a>0 基础</h2><p>第一行</p><p>指明脚本应使用的解释器的名字</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br></pre></td></tr></table></figure><p>编程规范：</p><ul><li>大写字母表示常量，小写字母表示变量</li></ul><h2 id="1-变量"><a href="#1-变量" class="headerlink" title="1 变量"></a>1 变量</h2><p><strong>变量</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意等号两边不能有空格</span></span><br><span class="line">foo=<span class="string">"yes"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$foo</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 有空格的字符串需要用引号包围</span></span><br><span class="line">b=<span class="string">"abc efg"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用其他变量的值</span></span><br><span class="line">c=<span class="string">"hhh <span class="variable">$b</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将执行命令的结果赋值</span></span><br><span class="line">d=$(ls -la)</span><br><span class="line">d1=`ls -la` <span class="comment"># ``等价 $()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 算数扩展，注意是两个括号</span></span><br><span class="line">e=$((5*7))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用&#123;&#125;限定变量名的范围</span></span><br><span class="line">f=aa.txt</span><br><span class="line">g=<span class="variable">$&#123;f&#125;</span>1</span><br></pre></td></tr></table></figure><p><strong>环境变量</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> xx=xxx<span class="comment"># 设置环境变量</span></span><br><span class="line"><span class="built_in">source</span> xxx_file<span class="comment"># 让文件中的环境变量立即生效</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$xx</span><span class="comment"># 输出变量的值</span></span><br></pre></td></tr></table></figure><p><strong>位置参数变量</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$n</span><span class="comment"># $0为命令本身；$1-$9代表第一到第九个参数；$&#123;10&#125;十以上的用大括号括起来</span></span><br><span class="line">$*<span class="comment"># 代表命令行中所有参数，并把所有参数看成一个整体</span></span><br><span class="line"><span class="variable">$@</span><span class="comment"># 代表命令行中所有参数，但把每个参数区分对待？</span></span><br><span class="line"><span class="variable">$#</span><span class="comment"># 参数个数</span></span><br></pre></td></tr></table></figure><p><strong>预定义变量</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$$<span class="comment"># 当前进程号</span></span><br><span class="line">$!<span class="comment"># 后台运行的最后一个进程的进程号</span></span><br><span class="line">$?<span class="comment"># 最后一次执行命令的返回状态，0代表成功，其他都是失败 可自定义</span></span><br></pre></td></tr></table></figure><h2 id="2-条件判断"><a href="#2-条件判断" class="headerlink" title="2 条件判断"></a>2 条件判断</h2><p><strong>运算符</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$((m+n))<span class="comment"># $(()) 中间写运算式</span></span><br><span class="line">$[m+n]<span class="comment"># 推荐这种方式</span></span><br><span class="line">expr m + n<span class="comment"># 不推荐</span></span><br></pre></td></tr></table></figure><p><strong>条件判断</strong></p><p>test</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写法一</span></span><br><span class="line"><span class="built_in">test</span> expression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写法二</span></span><br><span class="line">[ expression ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写法三</span></span><br><span class="line">[[ expression ]]<span class="comment"># 推荐使用这种写法，包含前两种的用法，且还支持模式匹配</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数字判断</span></span><br><span class="line">(( expression ))</span><br></pre></td></tr></table></figure><p>字符串判断</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[ -n string ]<span class="comment"># 如果字符串string的长度大于零，则为真</span></span><br><span class="line">[ -z string ]<span class="comment"># 如果字符串string的长度为零，则为真</span></span><br><span class="line">[ string1 = string2 ]<span class="comment"># 如果string1和string2相同，则为真</span></span><br><span class="line">[ string1 == string2 ] <span class="comment"># 等同于[ string1 = string2 ]</span></span><br><span class="line">[ string1 != string2 ]<span class="comment"># 如果string1和string2不相同，则为真</span></span><br><span class="line">[ string1 <span class="string">'&gt;'</span> string2 ]<span class="comment"># 如果按照字典顺序string1排列在string2之后，则为真</span></span><br><span class="line">[ string1 <span class="string">'&lt;'</span> string2 ]<span class="comment"># 如果按照字典顺序string1排列在string2之前，则为真</span></span><br></pre></td></tr></table></figure><p>整数判断</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(( m &gt; n ))<span class="comment"># 可以直接用 &gt; &lt; == &gt;= &lt;= !=，空格都要有！</span></span><br></pre></td></tr></table></figure><p>逻辑判断</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[ expr1 &amp;&amp; expr2 ]]<span class="comment"># &amp;&amp; || !</span></span><br></pre></td></tr></table></figure><h2 id="3-流控制"><a href="#3-流控制" class="headerlink" title="3 流控制"></a>3 流控制</h2><p>if</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [[ <span class="variable">$x</span> = 5 ]]; <span class="keyword">then</span><span class="comment"># 等号两边有空格，也可以用 == 代替</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"x=5"</span></span><br><span class="line"><span class="keyword">elif</span> [[ <span class="variable">$x</span> = 10 ]]; <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"x=10"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"no"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><p>case</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> $变量名 <span class="keyword">in</span></span><br><span class="line"><span class="string">"值 1"</span>）</span><br><span class="line">如果变量的值等于值 1，则执行程序 1</span><br><span class="line">;;</span><br><span class="line"></span><br><span class="line"><span class="string">"值 2"</span>）</span><br><span class="line">如果变量的值等于值 2，则执行程序 2</span><br><span class="line">;;</span><br><span class="line"></span><br><span class="line">*）</span><br><span class="line">如果变量的值都不是以上的值，则执行此程序</span><br><span class="line">;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><p>while</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">a=5</span><br><span class="line"><span class="keyword">while</span> [[ <span class="variable">$a</span>&gt;0 ]]; <span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$a</span></span><br><span class="line">a=$(( a-1 ))</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">echo</span> finish</span><br></pre></td></tr></table></figure><p>for</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (( i=0; i&lt;5; i++ )); <span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$i</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># =========================</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> A B C D; <span class="keyword">do</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$i</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> shell, linux, 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark</title>
      <link href="/2020/11/05/Spark/"/>
      <url>/2020/11/05/Spark/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><h2 id="一、SparkCore"><a href="#一、SparkCore" class="headerlink" title="一、SparkCore"></a>一、SparkCore</h2><h3 id="RDD-创建"><a href="#RDD-创建" class="headerlink" title="RDD 创建"></a>RDD 创建</h3><ul><li>从集合中创建</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(List(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">listRdd.foreach(println)</span><br><span class="line"></span><br><span class="line">val arrayRDD: RDD[Int] = sc.parallelize(Array(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">arrayRDD.foreach(println)</span><br></pre></td></tr></table></figure><ul><li>由外部存储系统的数据集创建</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val lines: RDD[String] = sc.textFile(<span class="string">"in"</span>)</span><br></pre></td></tr></table></figure><h3 id="RDD-转换算子"><a href="#RDD-转换算子" class="headerlink" title="RDD 转换算子"></a>RDD 转换算子</h3><h4 id="Value-类型"><a href="#Value-类型" class="headerlink" title="Value 类型"></a>Value 类型</h4><h5 id="map"><a href="#map" class="headerlink" title="map"></a>map</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(<span class="number">1</span> to <span class="number">10</span>)</span><br><span class="line">val mulRdd: RDD[Int] = listRdd.map(_ * <span class="number">2</span>)</span><br><span class="line">mulRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><h5 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h5><p>对每一个分区中的数据批处理。相当于只给每个分区的数据，只发送一次计算；而 map 的实现会给每个数据发送一次计算，增加了网络传输消耗；但是 mapPartitions 由于以整个分区为单位，可能会造成 OOM</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(<span class="number">1</span> to <span class="number">10</span>)</span><br><span class="line">val mapParRdd: RDD[Int] = listRdd.mapPartitions(datas =&gt; &#123;</span><br><span class="line">  datas.map(_ * <span class="number">2</span>)</span><br><span class="line">&#125;)</span><br><span class="line">mapParRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><h5 id="mapPartitionsWithIndex"><a href="#mapPartitionsWithIndex" class="headerlink" title="mapPartitionsWithIndex"></a>mapPartitionsWithIndex</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(<span class="number">1</span> to <span class="number">10</span>,<span class="number">3</span>)</span><br><span class="line">val tupleRdd: RDD[(Int, String)] = listRdd.mapPartitionsWithIndex &#123;</span><br><span class="line">  <span class="keyword">case</span> (num, datas) =&gt; &#123;</span><br><span class="line">    datas.map((_, <span class="string">"partition_num: "</span> + num))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">tupleRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><h5 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h5><p>扁平化，变成一个一个单独的元素</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[List[Int]] = sc.makeRDD(Array(List(<span class="number">1</span>, <span class="number">2</span>), List(<span class="number">3</span>, <span class="number">4</span>)))</span><br><span class="line">val flatRdd: RDD[Int] = listRdd.flatMap(datas =&gt; datas)</span><br><span class="line">flatRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><h5 id="glom"><a href="#glom" class="headerlink" title="glom"></a>glom</h5><p>将同一个分区的元素，放到一个数组里</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(<span class="number">1</span> to <span class="number">16</span>, <span class="number">4</span>)</span><br><span class="line">val glomRdd: RDD[Array[Int]] = listRdd.glom()</span><br><span class="line">glomRdd.collect().foreach(array =&gt; &#123;</span><br><span class="line">  println(array.mkString(<span class="string">","</span>))</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h5 id="groupBy"><a href="#groupBy" class="headerlink" title="groupBy"></a>groupBy</h5><p>同一个分区的放到一个迭代对象中。结果 tuple 中，第一个元素是 key，后面是 iterator</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(<span class="number">1</span> to <span class="number">9</span>)</span><br><span class="line">val groupRdd: RDD[(Int, Iterable[Int])] = listRdd.groupBy(i =&gt; i % <span class="number">2</span>)</span><br><span class="line">groupRdd.collect().foreach(println)</span><br><span class="line">--------------------</span><br><span class="line">(<span class="number">0</span>,CompactBuffer(<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">(<span class="number">1</span>,CompactBuffer(<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>))</span><br></pre></td></tr></table></figure><h5 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h5><p>按条件筛选</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(<span class="number">1</span> to <span class="number">9</span>)</span><br><span class="line">val filterRdd: RDD[Int] = listRdd.filter(_ % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">filterRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><h5 id="sample"><a href="#sample" class="headerlink" title="sample"></a>sample</h5><p>抽样。</p><p>参数介绍：withReplacement，是否重复抽样（可重复，泊松抽样；不可重复，伯努利抽样）</p><p>fraction，打分？（可重复下，需≥0，代表大概可重复的次数；不可重复下，需[0,1]，代表大概抽取比例）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(<span class="number">1</span> to <span class="number">10</span>)</span><br><span class="line"><span class="comment">// val sampleRdd: RDD[Int] = listRdd.sample(false, 0.7, 333)</span></span><br><span class="line">val sampleRdd: RDD[Int] = listRdd.sample(<span class="keyword">true</span>, <span class="number">4</span>, <span class="number">333</span>)</span><br><span class="line">sampleRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><h5 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h5><p>去重</p><p>注意：distinct 计算后，原数据分区会被打乱，是因为中间进行了 shuffle 操作。同时也因为 shuffle 导致必须等待所有分区都计算完成后才能进行下一个操作；而没有 shuffle 操作的算子，执行完一个分区的操作后就可以继续进行下一个操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(List(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">val disRdd: RDD[Int] = listRdd.distinct()</span><br><span class="line">val disRdd: RDD[Int] = listRdd.distinct(<span class="number">2</span>)  <span class="comment">// 设置去重后的分区数</span></span><br><span class="line">disRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><h5 id="coalease"><a href="#coalease" class="headerlink" title="coalease"></a>coalease</h5><p>缩减分区。实际为合并分区，即将其中某几个分区合并；若要扩大分区，需要添加 shuffle 参数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(<span class="number">1</span> to <span class="number">16</span>, <span class="number">4</span>)</span><br><span class="line">println(<span class="string">"before: "</span>, listRdd.partitions.size)</span><br><span class="line">val coalRdd: RDD[Int] = listRdd.coalesce(<span class="number">3</span>)</span><br><span class="line">println(<span class="string">"after: "</span>, coalRdd.partitions.size)</span><br></pre></td></tr></table></figure><h5 id="repartition"><a href="#repartition" class="headerlink" title="repartition"></a>repartition</h5><p>对 coalease 的封装，<code>shuffle = true</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.repartition(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><h5 id="sortBy"><a href="#sortBy" class="headerlink" title="sortBy"></a>sortBy</h5><p>排序，可自己设置排序规则</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val listRdd: RDD[Int] = sc.makeRDD(List(<span class="number">3</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">7</span>, <span class="number">2</span>))</span><br><span class="line">val sortRdd: RDD[Int] = listRdd.sortBy(x =&gt; x)</span><br><span class="line"><span class="comment">// val sortRdd: RDD[Int] = listRdd.sortBy(x =&gt; x%3)</span></span><br><span class="line">sortRdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><h4 id="双-Value-类型"><a href="#双-Value-类型" class="headerlink" title="双 Value 类型"></a>双 Value 类型</h4><h5 id="union"><a href="#union" class="headerlink" title="union"></a>union</h5><p>合并两个 Rdd</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val rdd3 = rdd1.union(rdd2)</span><br></pre></td></tr></table></figure><h5 id="subtract"><a href="#subtract" class="headerlink" title="subtract"></a>subtract</h5><p>去除相同元素，不同的会保留</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val rdd3 = rdd1.subtract(rdd2)</span><br></pre></td></tr></table></figure><h5 id="intersection"><a href="#intersection" class="headerlink" title="intersection"></a>intersection</h5><p>求交集后返回</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val rdd3 = rdd1.intersection(rdd2)</span><br></pre></td></tr></table></figure><h5 id="cartesian"><a href="#cartesian" class="headerlink" title="cartesian"></a>cartesian</h5><p>笛卡尔积</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val rdd3 = rdd1.cartesian(rdd2)</span><br></pre></td></tr></table></figure><h5 id="zip"><a href="#zip" class="headerlink" title="zip"></a>zip</h5><p>将两个 rdd 对应元素组合在一起（tuple？key-value？）。两个 rdd 分区数量和元素数量必须都相同；会把分区中的拆成一个一个的元素，组合的元素还在原来的分区里。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1: RDD[Int] = sc.makeRDD(Array(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), <span class="number">2</span>)</span><br><span class="line">val rdd2: RDD[String] = sc.makeRDD(Array(<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"d"</span>), <span class="number">2</span>)</span><br><span class="line">val zipRdd: RDD[(Int, String)] = rdd1.zip(rdd2)</span><br><span class="line">zipRdd.collect().foreach(println)</span><br><span class="line">zipRdd.saveAsTextFile(<span class="string">"output"</span>)</span><br></pre></td></tr></table></figure><h4 id="Key-Value-类型"><a href="#Key-Value-类型" class="headerlink" title="Key-Value 类型"></a>Key-Value 类型</h4><h5 id="partitionBy"><a href="#partitionBy" class="headerlink" title="partitionBy"></a>partitionBy</h5><p>根据 key 进行重新分区（因此 rdd 需要是 kv 的形式），也可自定义分区类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val arrayRdd: RDD[(Int, String)] = sc.makeRDD(Array((<span class="number">1</span>, <span class="string">"aaa"</span>), (<span class="number">2</span>, <span class="string">"bbb"</span>), (<span class="number">3</span>, <span class="string">"ccc"</span>), (<span class="number">4</span>, <span class="string">"ddd"</span>)), <span class="number">2</span>)</span><br><span class="line">val parRdd: RDD[(Int, String)] = arrayRdd.partitionBy(<span class="keyword">new</span> org.apache.spark.HashPartitioner(<span class="number">3</span>))</span><br><span class="line">parRdd.saveAsTextFile(<span class="string">"output"</span>)</span><br></pre></td></tr></table></figure><h3 id="Rdd-Action-行动算子"><a href="#Rdd-Action-行动算子" class="headerlink" title="Rdd Action 行动算子"></a>Rdd Action 行动算子</h3><h3 id="综合练习"><a href="#综合练习" class="headerlink" title="综合练习"></a>综合练习</h3><h2 id="二、SparkSQL"><a href="#二、SparkSQL" class="headerlink" title="二、SparkSQL"></a>二、SparkSQL</h2><p>Spark SQL是Spark用来处理结构化数据的一个模块，它提供了2个编程抽象：DataFrame和DataSet，并且作为分布式SQL查询引擎的作用。</p><p>Rdd → DataFrame → DataSet</p><ul><li>DataFrame：在 Rdd 的基础上，装饰了表结构，让每一个字段包含意义</li><li>DataSet：在 DataFrame 基础上，装饰了读取操作，让数据的读取像操作对象一样简单</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-shell</span><br></pre></td></tr></table></figure><h3 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h3><h4 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt; val df = spark.read.json(<span class="string">"/opt/module/spark-2.3.2-local/mydata/user.json"</span>)</span><br><span class="line">&gt; df.show</span><br><span class="line">==========</span><br><span class="line"><span class="comment"># user.json</span></span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"123"</span>, <span class="string">"age"</span>:20&#125;</span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"456"</span>, <span class="string">"age"</span>:20&#125;</span><br><span class="line">&#123;<span class="string">"name"</span>:<span class="string">"789"</span>, <span class="string">"age"</span>:20&#125;</span><br></pre></td></tr></table></figure><h4 id="SQL-风格语法"><a href="#SQL-风格语法" class="headerlink" title="SQL 风格语法"></a>SQL 风格语法</h4><ul><li>单个 Session 内 View 可见</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; df.createTempView(<span class="string">"user"</span>)</span><br><span class="line">&gt; spark.sql(<span class="string">"select * from user"</span>).show()</span><br></pre></td></tr></table></figure><ul><li>创建全局表</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; df.createGlobalTempView(<span class="string">"user_g"</span>)</span><br><span class="line">&gt; spark.newSession().sql(<span class="string">"SELECT * FROM global_temp.user_g"</span>).show()</span><br></pre></td></tr></table></figure><h4 id="DSL-风格语法"><a href="#DSL-风格语法" class="headerlink" title="DSL 风格语法"></a>DSL 风格语法</h4><p>以对象的方式来操作数据</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; df.select(<span class="string">"name"</span>).show()</span><br><span class="line">&gt; df.select($<span class="string">"name"</span>, $<span class="string">"age"</span> + <span class="number">1</span>).show()</span><br><span class="line">&gt; df.filter($<span class="string">"age"</span> &gt; <span class="number">21</span>).show()</span><br><span class="line">&gt; df.groupBy(<span class="string">"age"</span>).count().show()</span><br></pre></td></tr></table></figure><h4 id="Rdd-转为-DataFrame"><a href="#Rdd-转为-DataFrame" class="headerlink" title="Rdd 转为 DataFrame"></a>Rdd 转为 DataFrame</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">People</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">&gt;</span> <span class="title">val</span> <span class="title">rdd1</span> </span>= sc.makeRDD(<span class="type">List</span>((<span class="string">"zhangsan"</span>, <span class="number">20</span>), (<span class="string">"lisi"</span>, <span class="number">14</span>)))</span><br><span class="line">&gt; <span class="keyword">val</span> peopleRdd = rdd1.map(t=&gt;&#123;<span class="type">People</span>(t._1, t._2)&#125;)</span><br><span class="line">&gt; <span class="keyword">val</span> df = peopleRdd.toDF</span><br><span class="line">&gt; df.show</span><br></pre></td></tr></table></figure><h4 id="DataFrame-转为-Rdd"><a href="#DataFrame-转为-Rdd" class="headerlink" title="DataFrame 转为 Rdd"></a>DataFrame 转为 Rdd</h4><p>注意这里面转换之后，并不会还原成 People 结构，而只是一个 Row 对象。这是因为 DataFrame 本身不存数据的类型</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; df.rdd</span><br></pre></td></tr></table></figure><h3 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h3><p>Dataset是具有强类型的数据集合，需要提供对应的类型信息。</p><p>解决 DataFrame 中取数只能通过下标来取的问题（啥意思？？）</p><h4 id="创建-1"><a href="#创建-1" class="headerlink" title="创建"></a>创建</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">People</span>(<span class="params">name:<span class="type">String</span>, age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">&gt;</span> <span class="title">val</span> <span class="title">caseClassDS</span> </span>= <span class="type">Seq</span>(<span class="type">People</span>(<span class="string">"Andy"</span>, <span class="number">21</span>)).toDS()</span><br></pre></td></tr></table></figure><h4 id="Rdd-转换为-DataSet"><a href="#Rdd-转换为-DataSet" class="headerlink" title="Rdd 转换为 DataSet"></a>Rdd 转换为 DataSet</h4><p>Rdd + 结构 → DataFrame；DataFram + 类型 → DataSet</p><p>Rdd + 结构 + 类型 → DataSet</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">&gt;</span> <span class="title">val</span> <span class="title">mapRdd</span> </span>= rdd.map(t=&gt;&#123;<span class="type">Person</span>(t._1, t._2)&#125;)</span><br><span class="line">&gt; <span class="keyword">val</span> ds = mapRdd.toDS</span><br><span class="line">&gt; ds.show</span><br></pre></td></tr></table></figure><h4 id="DataSet-转换为-Rdd"><a href="#DataSet-转换为-Rdd" class="headerlink" title="DataSet 转换为 Rdd"></a>DataSet 转换为 Rdd</h4><p>转换回来仍保留着类型</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; ds.rdd</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark, 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive 常用操作 &amp; 练习</title>
      <link href="/2020/10/21/Hive%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%20&amp;%20%E7%BB%83%E4%B9%A0/"/>
      <url>/2020/10/21/Hive%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%20&amp;%20%E7%BB%83%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="一、常用操作"><a href="#一、常用操作" class="headerlink" title="一、常用操作"></a>一、常用操作</h2><h2 id="二、练习"><a href="#二、练习" class="headerlink" title="二、练习"></a>二、练习</h2>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> 练习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>console 日志输出到文件</title>
      <link href="/2020/10/09/Linux/console%20%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E5%88%B0%E6%96%87%E4%BB%B6/"/>
      <url>/2020/10/09/Linux/console%20%E6%97%A5%E5%BF%97%E8%BE%93%E5%87%BA%E5%88%B0%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">some_command 2&gt;&amp;1 | tee output.txt</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>在Linux中，如果想将一个程序在控制台中的输出字符输出到文件中，不保留控制台内的文字，可以用下面命令：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">some_command &gt; output.txt</span><br></pre></td></tr></table></figure><ul><li><p>命令结果会输出到<code>output.txt</code>中，换成<code>&gt;&gt;</code>可以追加到文件末尾</p></li><li><p>但如果想输出到文件同时，保留控制台的内容，需要使用tee命令，示例如下：</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">some_command | tee output.txt</span><br></pre></td></tr></table></figure><ul><li>有时会发现上述命令后屏幕有输出，但文件内容为空，此时可能是由于some_command输出的字符从std error文件描述符输出，需要先将std error的输出导向到std output：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">some_command 2&gt;&amp;1 | tee output.txt</span><br></pre></td></tr></table></figure><p>其中，2代表std error，1代表std output，&gt;&amp;是linux中fd到fd的重定向操作符。</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringBoot 集成 Prometheus</title>
      <link href="/2020/09/23/SpringBoot%E9%9B%86%E6%88%90Prometheus/"/>
      <url>/2020/09/23/SpringBoot%E9%9B%86%E6%88%90Prometheus/</url>
      
        <content type="html"><![CDATA[<h2 id="一、添加依赖"><a href="#一、添加依赖" class="headerlink" title="一、添加依赖"></a>一、添加依赖</h2><ul><li>Maven <code>pom.xml</code></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--  第一条必须加，否则会导致 Could not autowire. No beans of 'xxxx' type found 的错误  --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-actuator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.micrometer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>micrometer-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.micrometer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>micrometer-registry-prometheus<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>Gradle <code>build.gradle</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">implementation &apos;org.springframework.boot:spring-boot-starter-actuator&apos;</span><br><span class="line">compile &apos;io.micrometer:micrometer-registry-prometheus&apos;</span><br><span class="line">compile &apos;io.micrometer:micrometer-core&apos;</span><br></pre></td></tr></table></figure><ul><li>打开 Prometheus 监控接口 <code>application.properties</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">server.port=8088</span><br><span class="line">spring.application.name=springboot2-prometheus</span><br><span class="line">management.endpoints.web.exposure.include=*</span><br><span class="line">management.metrics.tags.application=$&#123;spring.application.name&#125;</span><br></pre></td></tr></table></figure><p>可以直接运行程序，访问<code>http://localhost:8088/actuator/prometheus</code>可以看到下面的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># HELP jvm_buffer_total_capacity_bytes An estimate of the total capacity of the buffers in this pool</span><br><span class="line"># TYPE jvm_buffer_total_capacity_bytes gauge</span><br><span class="line">jvm_buffer_total_capacity_bytes&#123;id=&quot;direct&quot;,&#125; 90112.0</span><br><span class="line">jvm_buffer_total_capacity_bytes&#123;id=&quot;mapped&quot;,&#125; 0.0</span><br><span class="line"># HELP tomcat_sessions_expired_sessions_total  </span><br><span class="line"># TYPE tomcat_sessions_expired_sessions_total counter</span><br><span class="line">tomcat_sessions_expired_sessions_total 0.0</span><br><span class="line"># HELP jvm_classes_unloaded_classes_total The total number of classes unloaded since the Java virtual machine has started execution</span><br><span class="line"># TYPE jvm_classes_unloaded_classes_total counter</span><br><span class="line">jvm_classes_unloaded_classes_total 1.0</span><br><span class="line"># HELP jvm_buffer_count_buffers An estimate of the number of buffers in the pool</span><br><span class="line"># TYPE jvm_buffer_count_buffers gauge</span><br><span class="line">jvm_buffer_count_buffers&#123;id=&quot;direct&quot;,&#125; 11.0</span><br><span class="line">jvm_buffer_count_buffers&#123;id=&quot;mapped&quot;,&#125; 0.0</span><br><span class="line"># HELP system_cpu_usage The &quot;recent cpu usage&quot; for the whole system</span><br><span class="line"># TYPE system_cpu_usage gauge</span><br><span class="line">system_cpu_usage 0.0939447637893599</span><br><span class="line"># HELP jvm_gc_max_data_size_bytes Max size of old generation memory pool</span><br><span class="line"># TYPE jvm_gc_max_data_size_bytes gauge</span><br><span class="line">jvm_gc_max_data_size_bytes 2.841116672E9</span><br><span class="line"></span><br><span class="line"># 此处省略超多字...</span><br></pre></td></tr></table></figure><h2 id="二、Prometheus-安装与配置"><a href="#二、Prometheus-安装与配置" class="headerlink" title="二、Prometheus 安装与配置"></a>二、Prometheus 安装与配置</h2><p>使用 docker 运行 Prometheus（仅初始测试）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name prometheus -d -p 9090:9090 prom/prometheus:latest</span><br></pre></td></tr></table></figure><p>写配置文件<code>prometheus.yml</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># my global config</span></span><br><span class="line">global:</span><br><span class="line">  scrape_interval:     15s <span class="comment"># Set the scrape interval to every 15 seconds. Default is every 1 minute.</span></span><br><span class="line">  evaluation_interval: 15s <span class="comment"># Evaluate rules every 15 seconds. The default is every 1 minute.</span></span><br><span class="line">  <span class="comment"># scrape_timeout is set to the global default (10s).</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load rules once and periodically evaluate them according to the global 'evaluation_interval'.</span></span><br><span class="line">rule_files:</span><br><span class="line">  <span class="comment"># - "first_rules.yml"</span></span><br><span class="line">  <span class="comment"># - "second_rules.yml"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A scrape configuration containing exactly one endpoint to scrape:</span></span><br><span class="line"><span class="comment"># Here it's Prometheus itself.</span></span><br><span class="line">scrape_configs:</span><br><span class="line">  <span class="comment"># The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.</span></span><br><span class="line">  - job_name: <span class="string">'prometheus'</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># metrics_path defaults to '/metrics'</span></span><br><span class="line">    <span class="comment"># scheme defaults to 'http'.</span></span><br><span class="line"></span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [<span class="string">'localhost:9090'</span>]</span><br><span class="line">  <span class="comment"># demo job</span></span><br><span class="line">  -  job_name: <span class="string">'springboot-actuator-prometheus-test'</span> <span class="comment"># job name</span></span><br><span class="line">     metrics_path: <span class="string">'/actuator/prometheus'</span> <span class="comment"># 指标获取路径</span></span><br><span class="line">     scrape_interval: 5s <span class="comment"># 间隔</span></span><br><span class="line">     basic_auth: <span class="comment"># Spring Security basic auth </span></span><br><span class="line">       username: <span class="string">'actuator'</span></span><br><span class="line">       password: <span class="string">'actuator'</span></span><br><span class="line">     static_configs:</span><br><span class="line">     - targets: [<span class="string">'docker.for.mac.localhost:18080'</span>] <span class="comment"># 实例的地址，默认的协议是http （这里开始有问题，直接写 localhost 是访问容器内的地址，而不是宿主机的。可通过在网页上方 status -&gt; targets 查看对应的服务情况</span></span><br></pre></td></tr></table></figure><p>运行 docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 9090:9090 -v $(<span class="built_in">pwd</span>)/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml</span><br></pre></td></tr></table></figure><p>访问 <code>http://localhost:9090</code>，可看到如下界面</p><p><img src="https://raw.githubusercontent.com/shuopic/ImgBed/master/NoteImgs/16fcafb94a6bf392.jpeg" alt="img"></p><ul><li>点击 <code>Insert metric at cursor</code> ，即可选择监控指标；点击 <code>Graph</code> ，即可让指标以图表方式展示；点击<code>Execute</code> 按钮，即可看到指标图</li></ul><h2 id="三、Grafana-安装和配置"><a href="#三、Grafana-安装和配置" class="headerlink" title="三、Grafana 安装和配置"></a>三、Grafana 安装和配置</h2><p>1、启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name=grafana -p 3000:3000 grafana/grafana</span><br></pre></td></tr></table></figure><p>2、登录</p><p>访问 <code>http://localhost:3000/login</code> ，初始账号/密码为：<code>admin/admin</code> </p><p>3、配置数据源</p><ul><li>点击左侧齿轮<code>Configuration</code>中<code>Add Data Source</code>，会看到如下界面：</li></ul><img src="https://raw.githubusercontent.com/shuopic/ImgBed/master/NoteImgs/image-20200924110615218.png" alt="image-20200924110615218" style="zoom: 25%;"><ul><li>这里我们选择Prometheus 当做数据源，这里我们就配置一下Prometheus 的访问地址，点击 <code>Save &amp; Test</code></li></ul><img src="https://raw.githubusercontent.com/shuopic/ImgBed/master/NoteImgs/image-20200924110807215.png" alt="image-20200924110807215" style="zoom:25%;"><p>4、创建监控 Dashboard</p><ul><li>点击导航栏上的 <code>+</code> 按钮，并点击Dashboard，将会看到类似如下的界面</li></ul><img src="https://raw.githubusercontent.com/shuopic/ImgBed/master/NoteImgs/image-20200924110949259.png" alt="image-20200924110949259" style="zoom:25%;"><ul><li>点击<code>+ Add new panel</code></li></ul><img src="https://raw.githubusercontent.com/shuopic/ImgBed/master/NoteImgs/image-20200924111151204.png" alt="image-20200924111151204" style="zoom:25%;"><h2 id="四、自定义监控指标"><a href="#四、自定义监控指标" class="headerlink" title="四、自定义监控指标"></a>四、自定义监控指标</h2><p>1、创建 Prometheus 监控管理类<code>PrometheusCustomMonitor</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io.micrometer.core.instrument.Counter;</span><br><span class="line"><span class="keyword">import</span> io.micrometer.core.instrument.DistributionSummary;</span><br><span class="line"><span class="keyword">import</span> io.micrometer.core.instrument.MeterRegistry;</span><br><span class="line"><span class="keyword">import</span> org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Component;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.PostConstruct;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PrometheusCustomMonitor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Counter requestErrorCount;</span><br><span class="line">    <span class="keyword">private</span> Counter orderCount;</span><br><span class="line">    <span class="keyword">private</span> DistributionSummary amountSum;</span><br><span class="line">    <span class="keyword">private</span> AtomicInteger failCaseNum;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> MeterRegistry registry;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PrometheusCustomMonitor</span><span class="params">(MeterRegistry registry)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.registry = registry;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostConstruct</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        requestErrorCount = registry.counter(<span class="string">"requests_error_total"</span>, <span class="string">"status"</span>, <span class="string">"error"</span>);</span><br><span class="line">        orderCount = registry.counter(<span class="string">"order_request_count"</span>, <span class="string">"order"</span>, <span class="string">"test-svc"</span>);</span><br><span class="line">        amountSum = registry.summary(<span class="string">"order_amount_sum"</span>, <span class="string">"orderAmount"</span>, <span class="string">"test-svc"</span>);</span><br><span class="line">        failCaseNum = registry.gauge(<span class="string">"fail_case_num"</span>, <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Counter <span class="title">getRequestErrorCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> requestErrorCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Counter <span class="title">getOrderCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> orderCount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> DistributionSummary <span class="title">getAmountSum</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> amountSum;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> AtomicInteger <span class="title">getFailCaseNum</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> failCaseNum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2、新增<code>/order</code>接口</p><p>当 <code>flag=&quot;1&quot;</code>时，抛异常，模拟下单失败情况。在接口中统计<code>order_request_count</code>和<code>order_amount_sum</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestMapping;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RequestParam;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.RestController;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.Resource;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> PrometheusCustomMonitor monitor;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@RequestMapping</span>(<span class="string">"/order"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">order</span><span class="params">(@RequestParam(defaultValue = <span class="string">"0"</span>)</span> String flag) <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 统计下单次数</span></span><br><span class="line">        monitor.getOrderCount().increment();</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">"1"</span>.equals(flag)) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"出错啦"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> amount = random.nextInt(<span class="number">100</span>);</span><br><span class="line">        <span class="comment">// 统计金额</span></span><br><span class="line">        monitor.getAmountSum().record(amount);</span><br><span class="line"></span><br><span class="line">        monitor.getFailCaseNum().set(amount);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"下单成功, 金额: "</span> + amount;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3、新增全局异常处理器<code>GlobalExceptionHandler</code></p><p>统计下单失败次数<code>requests_error_total</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ControllerAdvice;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ExceptionHandler;</span><br><span class="line"><span class="keyword">import</span> org.springframework.web.bind.annotation.ResponseBody;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.annotation.Resource;</span><br><span class="line"></span><br><span class="line"><span class="meta">@ControllerAdvice</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GlobalExceptionHandler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Resource</span></span><br><span class="line">    <span class="keyword">private</span> PrometheusCustomMonitor monitor;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ResponseBody</span></span><br><span class="line">    <span class="meta">@ExceptionHandler</span>(value = Exception.class)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">handle</span><span class="params">(Exception e)</span> </span>&#123;</span><br><span class="line">        monitor.getRequestErrorCount().increment();</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"error, message: "</span> + e.getMessage();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、测试</p><p>启动项目，访问<code>http://localhost:8080/order</code>和<code>http://localhost:8080/order?flag=1</code>模拟下单成功和失败的情况，然后我们访问<code>http://localhost:8080/actuator/prometheus</code>，可以看到我们自定义指标已经被 <code>/prometheus</code> 端点暴露出来</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># HELP requests_error_total  </span><br><span class="line"># TYPE requests_error_total counter</span><br><span class="line">requests_error_total&#123;application=&quot;springboot-actuator-prometheus-test&quot;,status=&quot;error&quot;,&#125; 41.0</span><br><span class="line"># HELP order_request_count_total  </span><br><span class="line"># TYPE order_request_count_total counter</span><br><span class="line">order_request_count_total&#123;application=&quot;springboot-actuator-prometheus-test&quot;,order=&quot;test-svc&quot;,&#125; 94.0</span><br><span class="line"># HELP order_amount_sum  </span><br><span class="line"># TYPE order_amount_sum summary</span><br><span class="line">order_amount_sum_count&#123;application=&quot;springboot-actuator-prometheus-test&quot;,orderAmount=&quot;test-svc&quot;,&#125; 53.0</span><br><span class="line">order_amount_sum_sum&#123;application=&quot;springboot-actuator-prometheus-test&quot;,orderAmount=&quot;test-svc&quot;,&#125; 2701.0</span><br></pre></td></tr></table></figure><p>5、使用 Prometheus 监控</p><p>重新运行 docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 9090:9090 -v $(<span class="built_in">pwd</span>)/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus --config.file=/etc/prometheus/prometheus.yml</span><br></pre></td></tr></table></figure><p>选择对应指标后可以看到数据变化</p><p>6、使用 Grafana 展示</p><p>在 Dashboard 界面选择对应的监控指标即可</p><hr><p>参考资料：</p><p><a href="https://prometheus.io/docs/concepts/metric_types/" target="_blank" rel="noopener">Metric types | Prometheus</a></p><p><a href="https://blog.csdn.net/typa01_kk/article/details/76696618" target="_blank" rel="noopener">IntelliJ IDEA创建第一个Spring Boot项目_Study Notes-CSDN博客</a></p><p><a href="https://cloud.tencent.com/developer/article/1508319" target="_blank" rel="noopener">Spring Boot 使用 Micrometer 集成 Prometheus 监控 Java 应用性能 【springboot 2.0】</a></p><p><a href="https://micrometer.io/docs/concepts" target="_blank" rel="noopener">Micrometer Application Monitoring【官方文档】</a></p><p><a href="https://juejin.im/post/6844904052417904653" target="_blank" rel="noopener">Spring Boot 微服务应用集成Prometheus + Grafana 实现监控告警 ★</a></p><p><a href="https://blog.kubernauts.io/https-blog-kubernauts-io-monitoring-java-spring-boot-applications-with-prometheus-part-1-c0512f2acd7b" target="_blank" rel="noopener">Monitoring Java Spring Boot applications with Prometheus: Part 1 | by Arush Salil | Kubernauts 【放弃这个教程？】client java 不支持 springboot 2.x，最高支持 1.5</a></p><p><a href="https://segmentfault.com/a/1190000015309478" target="_blank" rel="noopener">Spring Boot 参考指南（端点）_风继续吹 - SegmentFault 思否</a></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot, Prometheus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>虚拟机 Hadoop 环境配置</title>
      <link href="/2020/09/17/%E8%99%9A%E6%8B%9F%E6%9C%BAHadoop%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/09/17/%E8%99%9A%E6%8B%9F%E6%9C%BAHadoop%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="一、安装-CentOS-6-amp-基本配置"><a href="#一、安装-CentOS-6-amp-基本配置" class="headerlink" title="一、安装 CentOS 6 &amp; 基本配置"></a>一、安装 CentOS 6 &amp; 基本配置</h2><blockquote><p>win10通过VMware安装CentOS6.5 - 简书<br><a href="https://www.jianshu.com/p/9d5b9757a1ef" target="_blank" rel="noopener">https://www.jianshu.com/p/9d5b9757a1ef</a></p></blockquote><p>1、关闭防火墙</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop</span><br><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure><p>2、创建普通用户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useradd Ace</span><br><span class="line">passwd 123</span><br></pre></td></tr></table></figure><p>3、创建软件存储文件夹，并更改所有权</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/software /opt/module</span><br><span class="line">chown Ace:Ace /opt/software /opt/module</span><br></pre></td></tr></table></figure><p>4、用户添加到 sudoers</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sudoers</span><br><span class="line">Ace ALL=(ALL) NOPASSWD:ALL</span><br></pre></td></tr></table></figure><p>5、改 Hosts</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">for</span> ((i=101;i&lt;105;i++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"192.168.87.<span class="variable">$i</span> hadoop<span class="variable">$i</span>"</span> &gt;&gt; /etc/hosts</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>6、改静态 ip</p><p><code>vim /etc/sysconfig/network-scripts/ifcfg-eth0</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=eth0</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.87.100</span><br><span class="line">PREFIX=24</span><br><span class="line">GATEWAY=192.168.87.2</span><br><span class="line">DNS1=192.168.87.2</span><br><span class="line">NAME=<span class="string">"System eth0"</span></span><br></pre></td></tr></table></figure><p>【创建新虚拟机，下面的都要做一遍，可以写脚本解决（看下面，推荐）】</p><p>6、改 ip 地址（同上6）</p><p><code>vim /etc/sysconfig/network-scripts/ifcfg-eth0</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">IPADDR=192.168.87.100   <span class="comment"># 改成对应的</span></span><br></pre></td></tr></table></figure><p>7、改主机名</p><p><code>vim /etc/sysconfig/network</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HOSTNAME=hadoopxxx</span><br></pre></td></tr></table></figure><p>8、删除多余网卡</p><p><code>vim /etc/udev/rules.d/70-persistent-net.rules</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一行删掉（只保留一个网卡就行，注释也删掉，手动删的话记得和后面脚本的行数要对应上）</span></span><br><span class="line"><span class="comment"># 第二行最后 NAME="eth1" 改为 NAME="eth0"</span></span><br></pre></td></tr></table></figure><p>9、拍快照，克隆</p><p>【脚本】</p><ul><li>分发脚本 xsync</li></ul><p><code>vim xsync</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># 获取输入参数个数，如果没有参数，直接退出</span></span><br><span class="line">pcount=<span class="variable">$#</span></span><br><span class="line"><span class="keyword">if</span> ((pcount==0)); <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> no args;</span><br><span class="line"><span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">p1=<span class="variable">$1</span></span><br><span class="line">fname=`basename <span class="variable">$p1</span>`</span><br><span class="line"><span class="built_in">echo</span> fname=<span class="variable">$fname</span></span><br><span class="line"></span><br><span class="line">dirname=`<span class="built_in">cd</span> -P $(dirname <span class="variable">$p1</span>); <span class="built_in">pwd</span>`</span><br><span class="line"><span class="built_in">echo</span> dirname=<span class="variable">$dirname</span></span><br><span class="line"></span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((i=102;i&lt;105;i++)); <span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"------------- hadoop<span class="variable">$i</span> ------------"</span></span><br><span class="line">    rsync -avlP <span class="variable">$dirname</span>/<span class="variable">$fname</span> hadoop<span class="variable">$i</span>:<span class="variable">$dirname</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>移动到<code>bin</code>目录下，<code>sudo mv xsync /bin</code></p><p>安装<code>rsync</code>，<code>sudo yum install -y rsync</code></p><p>改权限，<code>chmod +x xsync</code></p><ul><li>执行相同命令脚本</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">pcount=<span class="variable">$#</span></span><br><span class="line"><span class="keyword">if</span> ((pcount==0)); <span class="keyword">then</span></span><br><span class="line"><span class="built_in">echo</span> no args;</span><br><span class="line"><span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"==== <span class="variable">$i</span> <span class="variable">$1</span> ===="</span></span><br><span class="line">        ssh <span class="variable">$i</span> <span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>移动到<code>/bin</code>，改权限</p><ul><li>自动配置网络脚本</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">id=<span class="variable">$1</span></span><br><span class="line"><span class="comment"># sed -i "s/before replace/after replace/"</span></span><br><span class="line">sudo sed -i <span class="string">"s/192.168.87.101/192.168.87.<span class="variable">$id</span>/"</span> /etc/sysconfig/network-scripts/ifcfg-eth0</span><br><span class="line">sudo sed -i <span class="string">"s/hadoop101/hadoop<span class="variable">$id</span>/"</span> /etc/sysconfig/network</span><br><span class="line"></span><br><span class="line">file=/etc/udev/rules.d/70-persistent-net.rules</span><br><span class="line"></span><br><span class="line"><span class="comment"># count "SUBSYSTEM" word number</span></span><br><span class="line">nu=$(grep -c SUBSYSTEM <span class="variable">$file</span>)</span><br><span class="line"><span class="keyword">if</span>((<span class="variable">$nu</span> &gt; 1));</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">        <span class="comment"># delete 8th line</span></span><br><span class="line">        sed -i <span class="string">'8d'</span> <span class="variable">$file</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">sed -i <span class="string">'s/eth1/eth0/'</span> <span class="variable">$file</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><p>改权限，<code>chmod +x change_network</code></p><h2 id="二、安装-JAVA-和-Hadoop"><a href="#二、安装-JAVA-和-Hadoop" class="headerlink" title="二、安装 JAVA 和 Hadoop"></a>二、安装 JAVA 和 Hadoop</h2><p>1、下载/上传 java 和 hadoop 的包到 <code>/opt/software</code></p><p>2、解压 java 和 hadoop 到 <code>/opt/module</code></p><p>3、安装（配置环境变量）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br><span class="line"><span class="comment"># 在末尾添加</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment"># HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure><p>4、测试安装情况</p><p>执行下面命令后，能出现版本号即为成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ java -version</span><br><span class="line">$ hadoop version</span><br></pre></td></tr></table></figure><p>5、使用 xsync 同步到多个机器上</p><h2 id="三、Hadoop-配置"><a href="#三、Hadoop-配置" class="headerlink" title="三、Hadoop 配置"></a>三、Hadoop 配置</h2><p><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener">Apache Hadoop 3.2.1 – Hadoop: Setting up a Single Node Cluster.</a></p><ul><li>安装插件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install ssh</span><br><span class="line">$ sudo yum install pdsh</span><br><span class="line">  </span><br><span class="line"><span class="comment"># pdsh 可能默认找不到</span></span><br><span class="line">$ wget http://mirrors.mit.edu/epel/6/i386/epel-release-6-8.noarch.rpm</span><br><span class="line">$ rpm -Uvh epel-release-6-8.noarch.rpm</span><br><span class="line">$ yum install pdsh</span><br></pre></td></tr></table></figure><ul><li>环境配置</li></ul><p><code>vim etc/hadoop/hadoop-env.sh</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/your-java-home-path</span><br></pre></td></tr></table></figure><h3 id="3-1-本地运行模式"><a href="#3-1-本地运行模式" class="headerlink" title="3.1 本地运行模式"></a>3.1 本地运行模式</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir input</span><br><span class="line">$ cp etc/hadoop/*.xml input</span><br><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output <span class="string">'dfs[a-z.]+'</span></span><br><span class="line">$ cat output/*</span><br></pre></td></tr></table></figure><h3 id="3-2-伪分布式"><a href="#3-2-伪分布式" class="headerlink" title="3.2 伪分布式"></a>3.2 伪分布式</h3><p>1、配置</p><p><code>vim etc/hadoop/core-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>etc/hadoop/hdfs-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>暂时不配置 yarn 了</strong></p><p><code>etc/hadoop/yarn-env.sh</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><p>2、设置免密码登录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -P <span class="string">''</span> -f ~/.ssh/id_rsa</span><br><span class="line">$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">$ chmod 0600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure><p>3、执行</p><ol><li><p>Format the filesystem:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs namenode -format</span><br></pre></td></tr></table></figure></li><li><p>Start NameNode daemon and DataNode daemon:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure><p>The hadoop daemon log output is written to the <code>$HADOOP_LOG_DIR</code> directory (defaults to <code>$HADOOP_HOME/logs</code>).</p></li><li><p>Browse the web interface for the NameNode; by default it is available at:</p><ul><li>NameNode - <code>http://localhost:9870/</code></li></ul></li><li><p>Make the HDFS directories required to execute MapReduce jobs:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -mkdir /user</span><br><span class="line">$ bin/hdfs dfs -mkdir /user/&lt;username&gt;</span><br></pre></td></tr></table></figure></li><li><p>Copy the input files into the distributed filesystem:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -mkdir input</span><br><span class="line">$ bin/hdfs dfs -put etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure></li><li><p>Run some of the examples provided:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output &apos;dfs[a-z.]+&apos;</span><br></pre></td></tr></table></figure></li><li><p>Examine the output files: Copy the output files from the distributed filesystem to the local filesystem and examine them:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -get output output</span><br><span class="line">$ cat output/*</span><br></pre></td></tr></table></figure><p>or View the output files on the distributed filesystem:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hdfs dfs -cat output/*</span><br></pre></td></tr></table></figure></li><li><p>When you’re done, stop the daemons with:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure></li></ol><h3 id="3-3-完全分布式"><a href="#3-3-完全分布式" class="headerlink" title="3.3 完全分布式"></a>3.3 完全分布式</h3><p>同步两个软件，/etc/profile</p><h4 id="3-3-1-集群配置"><a href="#3-3-1-集群配置" class="headerlink" title="3.3.1 集群配置"></a>3.3.1 集群配置</h4><ul><li>集群部署规划</li></ul><p>NN 1个； 2NN 1个；RM 1个；DN 3个、NM 3个 —— 最少共需六台机器，但是开不起那么多个虚拟机，因此按下表进行合并配置</p><table><thead><tr><th></th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode, DataNode</td><td>DataNode</td><td>SecondaryNameNode, DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager, NodeManager</td><td>NodeManager</td></tr></tbody></table><ul><li>配置集群</li></ul><p><strong>1）核心配置文件</strong></p><p>配置<code>etc/hadoop/core-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-2.7.2/data/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>2）HDFS配置文件</strong></p><p>配置``etc/hadoop/hadoop-env.sh`</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><p>配置<code>etc/hadoop/hdfs-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>3）YARN配置文件</strong></p><p>配置<code>etc/hadoop/yarn-env.sh</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><p>配置<code>etc/hadoop/yarn-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- Reducer获取数据的方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>4）MapReduce配置文件</strong></p><p>配置<code>etc/hadoop/mapred-env.sh</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><p>配置<code>etc/hadoop/mapred-site.xml</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ cp mapred-site.xml.template mapred-site.xml</span><br><span class="line">~</span><br><span class="line">~</span><br><span class="line"><span class="comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">~</span><br><span class="line">~</span><br></pre></td></tr></table></figure><ul><li>在集群上分发配置好的Hadoop配置文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ xsync /opt/module/hadoop-2.7.2/</span><br></pre></td></tr></table></figure><h4 id="3-3-2-集群单点启动"><a href="#3-3-2-集群单点启动" class="headerlink" title="3.3.2 集群单点启动"></a>3.3.2 集群单点启动</h4><p>1）如果集群是第一次启动，需要格式化NameNode</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop namenode -format</span><br></pre></td></tr></table></figure><p>2）在 hadoop102 上启动 NameNode</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure><p>3）在 hadoop102、hadoop103、hadoop104 上<strong>分别</strong>启动DataNode</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure><p>4）在 hadoop104 上启动 secondarynamenode</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop-daemon.sh start secondarynamenode</span><br></pre></td></tr></table></figure><p>5）查看服务启动情况 jps</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[hadoop102]$ jps</span><br><span class="line">4182 Jps</span><br><span class="line">2842 DataNode</span><br><span class="line">2747 NameNode</span><br><span class="line"></span><br><span class="line">[hadoop103]$ jps</span><br><span class="line">1712 DataNode</span><br><span class="line">2215 Jps</span><br><span class="line"></span><br><span class="line">[hadoop104]$ jps</span><br><span class="line">1680 DataNode</span><br><span class="line">2266 Jps</span><br><span class="line">2171 SecondaryNameNode</span><br></pre></td></tr></table></figure><h4 id="3-3-3-集群一键启动"><a href="#3-3-3-集群一键启动" class="headerlink" title="3.3.3 集群一键启动"></a>3.3.3 集群一键启动</h4><ul><li>配置机器间 ssh 无密登录</li></ul><p>「方法1：共用一个秘钥」</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成秘钥</span></span><br><span class="line">$ ssh-keygen -t rsa</span><br><span class="line"><span class="comment"># 将秘钥添加到本机的 authorized_keys 中，实现本机无密登录</span></span><br><span class="line">$ ssh-copy-id hadoop102</span><br><span class="line"><span class="comment"># 共享同一个秘钥，实现集群机器间无密登录</span></span><br><span class="line">$ xsync ~/.ssh</span><br></pre></td></tr></table></figure><p>「方法2：每个机器单独生成秘钥」</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在每个机器上生成秘钥（每个机器执行一遍）</span></span><br><span class="line">$ ssh-keygen -t rsa</span><br><span class="line"><span class="comment"># 把每个机器的秘钥分发到别的机器上（每个机器执行一遍）</span></span><br><span class="line">$ ssh-copy-id hadoop102</span><br><span class="line">$ ssh-copy-id hadoop103</span><br><span class="line">$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure><ul><li>添加机器名，配置<code>etc/hadoop/slaves</code>，并同步到其他机器（xsync）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure><ul><li>启动</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop102]$ start-dfs.sh</span><br><span class="line">[hadoop103]$ start-yarn.sh  <span class="comment"># 应该在ResouceManager所在的机器上启动YARN</span></span><br></pre></td></tr></table></figure><ul><li>测试（单词计数）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个文件夹 wcinput，里面放一个文件，添加计数文件中的内容，如：</span></span><br><span class="line">qwe</span><br><span class="line">ddd</span><br><span class="line">smo</span><br><span class="line">123</span><br><span class="line">qwe</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将这个文件夹上传到 hdfs</span></span><br><span class="line">$ hadoop fs -put wcinput/ /</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行 MapReduce 程序</span></span><br><span class="line">$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /wcinput /output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看执行结果</span></span><br><span class="line">[Ace@hadoop102 hadoop-2.7.2]$ hadoop fs -ls /output</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   3 Ace supergroup          0 2020-09-27 10:15 /output/_SUCCESS</span><br><span class="line">-rw-r--r--   3 Ace supergroup         24 2020-09-27 10:15 /output/part-r-00000</span><br><span class="line">[Ace@hadoop102 hadoop-2.7.2]$ hadoop fs -cat /output/part-r-00000</span><br><span class="line">1231</span><br><span class="line">ddd1</span><br><span class="line">qwe2</span><br><span class="line">smo1</span><br></pre></td></tr></table></figure><ul><li>停止</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop102]$ stop-dfs.sh</span><br><span class="line">[hadoop103]$ stop-yarn.sh</span><br></pre></td></tr></table></figure><h4 id="3-3-4-配置历史服务器-amp-日志聚集"><a href="#3-3-4-配置历史服务器-amp-日志聚集" class="headerlink" title="3.3.4 配置历史服务器 &amp; 日志聚集"></a>3.3.4 配置历史服务器 &amp; 日志聚集</h4><ul><li>配置<code>etc/hadoop/mapred-site.xml</code>，添加：</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>配置<code>etc/hadoop/yarn-site.xml</code></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 日志聚集功能使能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 日志保留时间设置7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li><p>[分发配置]</p></li><li><p>启动</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop102]$ start-dfs.sh</span><br><span class="line">[hadoop103]$ start-yarn.sh</span><br><span class="line">[hadoop104]$ mr-jobhistory-daemon.sh start historyserver</span><br><span class="line">$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /wcinput /output1</span><br></pre></td></tr></table></figure><ul><li>查看<ul><li>打开 yarn web <a href="http://hadoop103:8088/" target="_blank" rel="noopener">http://hadoop103:8088/</a></li><li>打开 history，在点 log 就能看到任务具体的日志信息了</li><li>![image-20201008173041985](../../../../../Library/Application Support/typora-user-images/image-20201008173041985.png)</li></ul></li></ul><h4 id="3-3-5-集群时间同步"><a href="#3-3-5-集群时间同步" class="headerlink" title="3.3.5 集群时间同步"></a>3.3.5 集群时间同步</h4><p>1）检查 ntp 是否安装</p><p>查看 ntp 包（切换到 root 用户）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]<span class="comment"># rpm -qa | grep ntp</span></span><br><span class="line">ntp-4.2.6p5-15.el6.centos.x86_64</span><br><span class="line">ntpdate-4.2.6p5-15.el6.centos.x86_64</span><br></pre></td></tr></table></figure><p>如果没有这两个服务要安装一下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ntp</span><br></pre></td></tr></table></figure><p>先停止 ntp 服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 ntpd 服务是否在运行</span></span><br><span class="line">$ service ntpd status</span><br><span class="line"><span class="comment"># 如果在运行先关闭</span></span><br><span class="line">$ service ntpd stop</span><br><span class="line">$ chkconfig ntpd off</span><br><span class="line"><span class="comment"># 再查看一下 ntpd 运行情况</span></span><br><span class="line">$ chkconfig --list ntpd</span><br></pre></td></tr></table></figure><p>2）修改ntp配置文件<code>/etc/ntp.conf</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）</span></span><br><span class="line">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改2（集群在局域网中，不使用其他互联网上的时间），将下面四行注释掉</span></span><br><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</span></span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure><p>3）修改<code>/etc/sysconfig/ntpd</code>文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">增加内容如下（让硬件时间与系统时间一起同步）</span><br><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure><p>4）重新启动ntpd服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ service ntpd status</span><br><span class="line">$ service ntpd start</span><br></pre></td></tr></table></figure><p>5）设置ntpd服务开机启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop102]$ chkconfig ntpd on</span><br></pre></td></tr></table></figure><p>6）其他机器配置（必须root用户）</p><p>在其他机器配置10分钟与时间服务器同步一次</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ crontab -e</span><br><span class="line">*/10 * * * * /usr/sbin/ntpdate hadoop102</span><br></pre></td></tr></table></figure><p>测试（修改任意机器时间），十分钟后查看机器是否与时间服务器同步</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ date -s <span class="string">"2017-9-11 11:11:11"</span></span><br></pre></td></tr></table></figure><p>7）若主机时间不对</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ service ntpd stop</span><br><span class="line">$ ntpdate us.pool.ntp.org</span><br><span class="line">$ service ntpd start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者直接</span></span><br><span class="line">$ sudo ntpdate -u pool.ntp.org</span><br></pre></td></tr></table></figure><h3 id="3-4-常用端口记录"><a href="#3-4-常用端口记录" class="headerlink" title="3.4 常用端口记录"></a>3.4 常用端口记录</h3><blockquote><p><a href="https://blog.csdn.net/yeruby/article/details/49406073" target="_blank" rel="noopener">Hadoop默认端口应用一览_在路上的学习者-CSDN博客</a></p><p><a href="https://blog.csdn.net/baiBenny/article/details/53887328" target="_blank" rel="noopener">Hadoop常用端口号_baiBenny的博客-CSDN博客</a></p></blockquote><table><thead><tr><th>组件</th><th>节点</th><th>默认端口</th><th>配置</th><th>用途说明</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode</td><td>50070</td><td>dfs.namenode.http-address</td><td>http服务的端口，可查看 HDFS 存储内容</td></tr><tr><td>HBase</td><td>Master</td><td>16000</td><td></td><td>Master RPC Port（远程通信调用）</td></tr><tr><td></td><td>Master</td><td>16010</td><td></td><td>Master Web Port</td></tr><tr><td></td><td>Regionserver</td><td>16020</td><td></td><td>Regionserver RPC Port</td></tr><tr><td></td><td>Regionserver</td><td>16030</td><td></td><td>Regionserver Web Port</td></tr><tr><td>Spark</td><td></td><td>4040</td><td></td><td>查看 Spark Job</td></tr></tbody></table><h3 id="3-5-HA"><a href="#3-5-HA" class="headerlink" title="3.5 HA"></a>3.5 HA</h3><ul><li>配置两个 NameNode</li><li>配置 JournalNode 用于将 Active NN 的数据 同步到 Standby NN 上「解决元数据同步的问题」</li><li>配置 Zookeeper，解决主备 NN 切换的问题，防止脑裂</li><li>在 NN 上启动 failoverController（zkfc），作为 Zookeeper 的客户端，实现与 zk 集群的交互和监测</li></ul><img src="https://raw.githubusercontent.com/shuopic/ImgBed/master/NoteImgs/image-20201110104755190.png" alt="image-20201110104755190" style="zoom: 33%;"><h2 id="四、Zookeeper-配置"><a href="#四、Zookeeper-配置" class="headerlink" title="四、Zookeeper 配置"></a>四、Zookeeper 配置</h2><h3 id="4-1-本地模式"><a href="#4-1-本地模式" class="headerlink" title="4.1 本地模式"></a>4.1 本地模式</h3><p><strong>1、安装前准备</strong></p><ul><li>安装Jdk</li><li>拷贝Zookeeper安装包到Linux系统下</li><li>解压到指定目录</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-3.4.10.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure><p><strong>2、配置修改</strong></p><ul><li>修改<code>conf/zoo_sample.cfg</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure><ul><li>修改 zoo.cfg 文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/opt/module/zookeeper-3.4.10/zkData</span><br></pre></td></tr></table></figure><p>并创建 zkData 文件夹</p><p><strong>3、操作Zookeeper</strong></p><ul><li>启动Zookeeper</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/zkServer.sh start</span><br></pre></td></tr></table></figure><ul><li>查看进程是否启动</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ jps</span><br><span class="line">4020 Jps</span><br><span class="line">4001 QuorumPeerMain</span><br></pre></td></tr></table></figure><ul><li>查看状态：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ bin/zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: standalone</span><br></pre></td></tr></table></figure><ul><li>停止Zookeeper</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/zkServer.sh stop</span><br></pre></td></tr></table></figure><h3 id="4-2-集群模式"><a href="#4-2-集群模式" class="headerlink" title="4.2 集群模式"></a>4.2 集群模式</h3><p><strong>1、配置</strong></p><ul><li>修改 zoo.cfg 文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">server.2=hadoop102:2888:3888</span><br><span class="line">server.3=hadoop103:2888:3888</span><br><span class="line">server.4=hadoop104:2888:3888</span><br><span class="line"># 2888 为集群间通信端口号</span><br><span class="line"># 3888 为选举端口号</span><br><span class="line"># server.2/3/4 为id，不相同即可</span><br></pre></td></tr></table></figure><ul><li>创建 <code>zkData/myid</code>，每个机器写不同的，要和前面的对应上</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ vim zkData/myid</span><br><span class="line"><span class="comment"># hadoop102</span></span><br><span class="line">2</span><br><span class="line"><span class="comment"># hadoop103</span></span><br><span class="line">3</span><br><span class="line"><span class="comment"># hadoop104</span></span><br><span class="line">4</span><br></pre></td></tr></table></figure><ul><li>配置 <code>bin/zkEnv.sh</code></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 替换前</span></span><br><span class="line">ZOO_LOG_DIR=<span class="string">"."</span></span><br><span class="line"><span class="comment"># 替换后</span></span><br><span class="line">ZOO_LOG_DIR=<span class="string">"/opt/module/zookeeper-3.4.10/logs"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加 JAVA_HOME（远程启动的时候才是必要的，因为会丢失环境变量）</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><ul><li>同步 xsync</li></ul><p><strong>2、启动</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个机器都要单独启动</span></span><br><span class="line">./bin/zkServer.sh start</span><br></pre></td></tr></table></figure><p>仅启动一台机器时：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ./zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Error contacting service. It is probably not running.</span><br></pre></td></tr></table></figure><p>启动两台机器（超过半数）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ./zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/module/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: leader / follower</span><br></pre></td></tr></table></figure><h3 id="4-3-客户端操作"><a href="#4-3-客户端操作" class="headerlink" title="4.3 客户端操作"></a>4.3 客户端操作</h3><ul><li>启动</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/zkCli.sh</span><br></pre></td></tr></table></figure><ul><li>执行</li></ul><table><thead><tr><th>命令基本语法</th><th>功能描述</th></tr></thead><tbody><tr><td>help</td><td>显示所有操作命令</td></tr><tr><td>ls path [watch]</td><td>使用 ls 命令来查看当前znode中所包含的内容</td></tr><tr><td>ls2 path [watch]</td><td>查看当前节点数据并能看到更新次数等数据</td></tr><tr><td>create</td><td>普通创建<br>-s  含有序列<br>-e  临时（重启或者超时消失）</td></tr><tr><td>get path [watch]</td><td>获得节点的值</td></tr><tr><td>set</td><td>设置节点的具体值</td></tr><tr><td>stat</td><td>查看节点状态</td></tr><tr><td>delete</td><td>删除节点</td></tr><tr><td>rmr</td><td>递归删除节点</td></tr></tbody></table><h2 id="五、Kakfa-配置"><a href="#五、Kakfa-配置" class="headerlink" title="五、Kakfa 配置"></a>五、Kakfa 配置</h2><h3 id="5-1-环境准备"><a href="#5-1-环境准备" class="headerlink" title="5.1 环境准备"></a>5.1 环境准备</h3><ul><li>在 hadoop102 103 104 上均安装 Kafka</li><li>jar 包下载 <a href="https://kafka.apache.org/downloads" target="_blank" rel="noopener">https://kafka.apache.org/downloads</a><ul><li>命名中有两个版本号，第一个为 scala 版本，第二个是 kafka 版本</li></ul></li></ul><h3 id="5-2-集群配置"><a href="#5-2-集群配置" class="headerlink" title="5.2 集群配置"></a>5.2 集群配置</h3><ul><li>修改 <code>config/server.properties</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># broker的全局唯一编号，不能重复</span><br><span class="line">broker.id=0</span><br><span class="line"></span><br><span class="line"># 删除topic功能使能（kafka 2.x 版本 不需要配置）</span><br><span class="line">delete.topic.enable=true</span><br><span class="line"></span><br><span class="line"># kafka运行时数据存放的路径</span><br><span class="line">log.dirs=/opt/module/kafka_2.12-2.3.1/data</span><br><span class="line"></span><br><span class="line"># 配置连接Zookeeper集群地址</span><br><span class="line">zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181</span><br></pre></td></tr></table></figure><ul><li><p>分发安装包到所有物理机上 xsync</p></li><li><p>将 hadoop103 104 上<code>config/server.properties</code> 中的 <code>broker.id=x</code>进行修改</p></li></ul><p><strong>单点启动 / 停止</strong> </p><p>依次在 hadoop102、hadoop103、hadoop104 节点上启动/停止 kafka，执行下面的命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line"><span class="comment"># 前台运行</span></span><br><span class="line">$ bin/kafka-server-start.sh config/server.properties</span><br><span class="line"><span class="comment"># 后台运行</span></span><br><span class="line">$ bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止</span></span><br><span class="line">$ bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure><p><strong>群起 / 群停</strong></p><p>由于 Kafka 中没有给集群启动停止的脚本，需要自己写<code>kk-all.sh</code></p><p>需要注意：要先在 <code>~/.bashrc</code> 中配置 java 环境变量（xsync）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">"start"</span>)&#123;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"==== start <span class="variable">$i</span> kafka ===="</span></span><br><span class="line">                <span class="comment"># ssh $i "source /etc/profile"</span></span><br><span class="line">                ssh <span class="variable">$i</span> <span class="string">"/opt/module/kafka_2.12-2.3.1/bin/kafka-server-start.sh -daemon /opt/module/kafka_2.12-2.3.1/config/server.properties"</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"></span><br><span class="line"><span class="string">"stop"</span>)&#123;</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"==== stop <span class="variable">$i</span> kafka ===="</span></span><br><span class="line">                <span class="comment"># ssh $i "source /etc/profile"</span></span><br><span class="line">                ssh <span class="variable">$i</span> <span class="string">"/opt/module/kafka_2.12-2.3.1/bin/kafka-server-stop.sh"</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">&#125;;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><p>启动/停止 Kafka：（记得先启动 Zookeeper）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ ./kk-all.sh start</span><br><span class="line">$ jps</span><br><span class="line">1637 QuorumPeerMain</span><br><span class="line">6071 Kafka</span><br><span class="line">6538 Jps</span><br><span class="line"></span><br><span class="line">$ ./kk-all.sh stop</span><br></pre></td></tr></table></figure><h3 id="5-3-命令行操作"><a href="#5-3-命令行操作" class="headerlink" title="5.3 命令行操作"></a>5.3 命令行操作</h3><ul><li>查看当前服务器中的所有 topic</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --list</span><br></pre></td></tr></table></figure><ul><li>创建 topic</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --create --replication-factor 3 --partitions 1 --topic first</span><br></pre></td></tr></table></figure><p><code>--replication-factor</code> 定义副本数；<code>--partitions</code> 定义分区数</p><ul><li>删除 topic</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --delete --topic first</span><br></pre></td></tr></table></figure><ul><li>查看某个 Topic 的详情</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/kafka-topics.sh --zookeeper hadoop102:2181 --describe --topic first</span><br></pre></td></tr></table></figure><ul><li>发送消息</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ bin/kafka-console-producer.sh --broker-list hadoop102:9092 --topic first</span><br><span class="line">&gt;hello world</span><br><span class="line">&gt;atguigu atguigu</span><br></pre></td></tr></table></figure><ul><li>消费消息</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic first</span><br></pre></td></tr></table></figure><p><code>--from-beginning</code> 会把 first 主题中以往所有的数据都读取出来</p><h2 id="六、Spark-配置"><a href="#六、Spark-配置" class="headerlink" title="六、Spark 配置"></a>六、Spark 配置</h2><h3 id="6-1-环境准备"><a href="#6-1-环境准备" class="headerlink" title="6.1 环境准备"></a>6.1 环境准备</h3><p>下载地址：<a href="https://archive.apache.org/dist/spark/" target="_blank" rel="noopener">https://archive.apache.org/dist/spark/</a></p><p>有两种版本，hadoop 版下载就能用，不依赖其他组价；without-hadoop 需要依赖已有的 hadoop 组件</p><blockquote><p>spark-2.3.2-bin-hadoop2.7.tgz<br>spark-2.3.2-bin-without-hadoop.tgz </p></blockquote><h3 id="6-2-本地模式-Local"><a href="#6-2-本地模式-Local" class="headerlink" title="6.2 本地模式 Local"></a>6.2 本地模式 Local</h3><ul><li>Jar</li></ul><p>解压后进入 Spark 根目录执行（一个算 PI 的程序）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master <span class="built_in">local</span>[2] \</span><br><span class="line">./examples/jars/spark-examples_2.11-2.3.2.jar 100</span><br><span class="line"></span><br><span class="line">bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.3.2.jar 100</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一大堆迭代过程 </span></span><br><span class="line">Pi is roughly 3.1424043142404314</span><br></pre></td></tr></table></figure><p>可以通过访问 <a href="http://hadoop102:4040" target="_blank" rel="noopener">http://hadoop102:4040</a> 查看任务运行情况</p><p><strong>「问题」</strong>：运行结束这个页面就关闭了，不能查历史任务执行情况</p><p><strong>「解决」</strong>：添加 Spark History Server</p><ul><li>Spark-shell</li></ul><p>进入 Spark-shell，<code>bin/spark-shell</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建两个文件，里面输入几行单词</span></span><br><span class="line">$ vim 1.txt  <span class="comment"># xxxxx</span></span><br><span class="line">$ vim 2.txt  <span class="comment"># xxxxx</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入 spark-shell 执行</span></span><br><span class="line">$ bin/spark-shell</span><br><span class="line">&gt; sc.textFile(<span class="string">"input"</span>).flatMap(_.split(<span class="string">" "</span>)).map((_,1)).reduceByKey(_+_).collect</span><br></pre></td></tr></table></figure><h3 id="6-3-Standalone-模式"><a href="#6-3-Standalone-模式" class="headerlink" title="6.3 Standalone 模式"></a>6.3 Standalone 模式</h3><p>构建一个由 Master + Slave 构成的 Spark 集群，Spark 运行在集群中。</p><p>这个要和 Hadoop 中的 Standalone 区别开来.这里的 Standalone 是指只用 Spark 来搭建一个集群, 不需要借助其他的框架.是相对于 Yarn 和 Mesos 来说的.</p><h4 id="6-3-1-Spark-server配置"><a href="#6-3-1-Spark-server配置" class="headerlink" title="6.3.1 Spark server配置"></a>6.3.1 Spark server配置</h4><p>1、进入配置文件目录conf，配置spark-evn.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> conf/</span><br><span class="line">cp spark-env.sh.template spark-env.sh</span><br></pre></td></tr></table></figure><p>在 <code>spark-env.sh</code> 文件中配置如下内容:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SPARK_MASTER_HOST=hadoop102</span><br><span class="line">SPARK_MASTER_PORT=7077 <span class="comment"># 默认端口就是7077, 可以省略不配</span></span><br></pre></td></tr></table></figure><p>2、修改 slaves 文件，添加 worker 节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cp slaves.template slaves</span><br><span class="line"><span class="comment"># 在slaves文件中配置如下内容:</span></span><br><span class="line">hadoop201</span><br><span class="line">hadoop202</span><br><span class="line">hadoop203</span><br></pre></td></tr></table></figure><p>3、修改 sbin/spark-config.sh，添加 JAVA_HOME （防止 JAVA_HOME is not set 报错）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_144</span><br></pre></td></tr></table></figure><p>4、分发spark-standalone</p><p>5、启动 Spark 集群</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></figure><p>6、网页查看信息：<a href="http://hadoop102:8080/" target="_blank" rel="noopener">http://hadoop102:8080/</a></p><p>7、测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master spark://hadoop102:7077 \</span><br><span class="line">--executor-memory 1G \</span><br><span class="line">--total-executor-cores 6 \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">./examples/jars/spark-examples_2.11-2.3.2.jar 100</span><br></pre></td></tr></table></figure><h4 id="6-3-2-spark-history-server"><a href="#6-3-2-spark-history-server" class="headerlink" title="6.3.2 spark-history-server"></a>6.3.2 spark-history-server</h4><p>在 Spark-shell 没有退出之前，看到正在执行的任务的日志情况:<a href="http://hadoop102:4040" target="_blank" rel="noopener">http://hadoop102:4040</a>. 但是退出之后，执行的所有任务记录全部丢失</p><p>所以需要配置任务的历史服务器, 方便在任何需要的时候去查看日志。</p><ul><li>配置spark-default.conf文件，开启 Log</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-defaults.conf.template spark-defaults.conf</span><br></pre></td></tr></table></figure><p>在 <code>spark-defaults.conf</code> 文件中, 添加如下内容:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark.eventLog.enabled           <span class="literal">true</span></span><br><span class="line">spark.eventLog.dir               hdfs://hadoop102:9000/spark-job-log</span><br></pre></td></tr></table></figure><p>注意:</p><p><code>hdfs://hadoop201:9000/spark-job-log</code> 目录必须提前存在, 名字随意</p><ul><li>修改spark-env.sh文件，添加如下配置</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HISTORY_OPTS=<span class="string">"-Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=30 -Dspark.history.fs.logDirectory=hdfs://hadoop102:9000/spark-job-log"</span></span><br></pre></td></tr></table></figure><ul><li>分发配置文件</li><li>启动历史服务<ul><li>需要先启动 HDFS <code>$HADOOP_HOME/sbin/start-dfs.sh</code></li><li>然后再启动: <code>sbin/start-history-server.sh</code></li></ul></li></ul><p>ui 地址: <a href="http://hadoop102:18080" target="_blank" rel="noopener">http://hadoop102:18080</a></p><h3 id="6-4-Yarn-模式"><a href="#6-4-Yarn-模式" class="headerlink" title="6.4 Yarn 模式"></a>6.4 Yarn 模式</h3><h4 id="6-4-1-spark-server-配置"><a href="#6-4-1-spark-server-配置" class="headerlink" title="6.4.1 spark server 配置"></a>6.4.1 spark server 配置</h4><ul><li>修改 <code>${HADOOP_HOME}/etc/hadoop/yarn-site.xml</code>（仅虚拟机中配置，防止内存不够）</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默&gt;认是true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默&gt;认是true --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>修改 <code>conf/spark-env.sh</code>，分发</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">YARN_CONF_DIR=/opt/module/hadoop-2.7.2/etc/hadoop</span><br></pre></td></tr></table></figure><ul><li>测试（注意 master、deploy-mode 参数的变化）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ start-dfs.sh</span><br><span class="line">$ start-yarn.sh</span><br><span class="line"></span><br><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode client \</span><br><span class="line">./examples/jars/spark-examples_2.11-2.3.2.jar 100</span><br></pre></td></tr></table></figure><ul><li>spark-shell</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/spark-shell --master yarn</span><br></pre></td></tr></table></figure><p>Yarn：<a href="http://hadoop103:8088" target="_blank" rel="noopener">http://hadoop103:8088</a></p><h4 id="6-4-2-spark-history-server"><a href="#6-4-2-spark-history-server" class="headerlink" title="6.4.2 spark-history-server"></a>6.4.2 spark-history-server</h4><p><code>$HADOOP_HOME/etc/hadoop/yarn-site.xml</code> 中添加</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop104:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 填 yarn historyserver 的物理机  --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>$SPARK_HOME/conf/spark-defaults.conf</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">spark.yarn.historyServer.addresshadoop102:18080    # spark history Server 物理机</span><br><span class="line">spark.history.ui.port 18080</span><br><span class="line">spark.eventLog.enabled true</span><br><span class="line">spark.eventLog.dir               hdfs://hadoop102:9000/spark-job-log</span><br><span class="line">spark.history.fs.logDirectory hdfs://hadoop102:9000/spark-job-log</span><br></pre></td></tr></table></figure><ul><li>相关服务<ul><li>spark: <code>sbin/start-all.sh</code></li><li>HDFS: <code>[hadoop102]$ start-dfs.sh</code></li><li>Yarn: <code>[hadoop103]$ start-yarn.sh</code></li><li>Yarn-history: <code>[hadoop104]$ mr-jobhistory-daemon.sh start historyserver</code></li><li>Spark-history: <code>[hadoop102] $ sbin/start-history-server.sh</code></li></ul></li></ul><p>【可以正常展示了】</p><p>相关文档解释：<a href="https://www.cnblogs.com/sorco/p/7070922.html" target="_blank" rel="noopener">spark深入：配置文件与日志 - Super_Orco - 博客园</a></p><ul><li>查看方式<ul><li>通过 YARN 查询<ul><li><a href="http://hadoop103:8088/" target="_blank" rel="noopener">http://hadoop103:8088/</a></li></ul></li><li>直接在 spark history server 中查询<ul><li><a href="http://hadoop102:18080/" target="_blank" rel="noopener">http://hadoop102:18080/</a></li></ul></li></ul></li></ul><h3 id="6-5-WordCount-程序"><a href="#6-5-WordCount-程序" class="headerlink" title="6.5 WordCount 程序"></a>6.5 WordCount 程序</h3><p>略</p><h2 id="七、Hive-配置"><a href="#七、Hive-配置" class="headerlink" title="七、Hive 配置"></a>七、Hive 配置</h2><h3 id="7-1-单机默认配置"><a href="#7-1-单机默认配置" class="headerlink" title="7.1 单机默认配置"></a>7.1 单机默认配置</h3><p>下载地址：<a href="http://archive.apache.org/dist/hive/" target="_blank" rel="noopener">http://archive.apache.org/dist/hive/</a></p><p><strong>安装部署：</strong></p><ul><li>修改 <code>conf/hive-env.sh.template</code> </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ mv hive-env.sh.template hive-env.sh</span><br><span class="line">$ vim hive-env.sh</span><br><span class="line">~</span><br><span class="line">~</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line"><span class="built_in">export</span> HIVE_CONF_DIR=/opt/module/hive-2.3.0-bin/conf</span><br><span class="line">~</span><br><span class="line">~</span><br></pre></td></tr></table></figure><ul><li>hadoop 相关配置</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动 hdfs yarn</span></span><br><span class="line">$ start-dfs.sh</span><br><span class="line">$ start-yarn.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 hive warehouse（存数据的地方）</span></span><br><span class="line">$ hadoop fs -mkdir /tmp</span><br><span class="line">$ hadoop fs -mkdir -p /user/hive/warehouse</span><br><span class="line">$ hadoop fs -chmod g+w /tmp</span><br><span class="line">$ hadoop fs -chmod g+w /user/hive/warehouse</span><br></pre></td></tr></table></figure><ul><li>Hive 基本操作 </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hive</span><br><span class="line"><span class="comment"># 查看数据库</span></span><br><span class="line">hive&gt; show databases;</span><br><span class="line"><span class="comment"># 打开默认数据库 </span></span><br><span class="line">hive&gt; use default;</span><br><span class="line"><span class="comment"># 显示 default 数据库中的表 </span></span><br><span class="line">hive&gt; show tables;</span><br><span class="line"><span class="comment"># 创建一张表</span></span><br><span class="line">hive&gt; create table student(id int, name string);</span><br><span class="line"><span class="comment"># 查看表的结构 </span></span><br><span class="line">hive&gt; desc student;</span><br><span class="line"><span class="comment"># 向表中插入数据</span></span><br><span class="line">hive&gt; insert into student values(1000,<span class="string">"ss"</span>);</span><br><span class="line"><span class="comment"># 查询表中数据</span></span><br><span class="line">hive&gt; select * from student;</span><br><span class="line"><span class="comment"># 退出 </span></span><br><span class="line">hive hive&gt; quit;</span><br></pre></td></tr></table></figure><h3 id="7-2-修改默认数据库（derby-gt-MySQL）"><a href="#7-2-修改默认数据库（derby-gt-MySQL）" class="headerlink" title="7.2 修改默认数据库（derby -&gt; MySQL）"></a>7.2 修改默认数据库（derby -&gt; MySQL）</h3><p>derby 只支持单个客户端连接，仅适用于简单测试。更换成关系型数据库（如MySQL），可支持多客户端连接。</p><h4 id="7-2-1-安装-MySQL"><a href="#7-2-1-安装-MySQL" class="headerlink" title="7.2.1 安装 MySQL"></a>7.2.1 安装 MySQL</h4><ul><li>卸载原有的，安装新的 MySQL </li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卸载原有的</span></span><br><span class="line">$ su -  <span class="comment"># 切换到 root 用户</span></span><br><span class="line">$ rpm -qa | grep mysql </span><br><span class="line">mysql-libs-5.1.73-7.el6.x86_64</span><br><span class="line">$ rpm -e --nodeps mysql-libs-5.1.73-7.el6.x86_64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装新的 MySQL-server</span></span><br><span class="line">$ rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm</span><br><span class="line">cat /root/.mysql_secret <span class="comment"># 记住默认的root登录密码</span></span><br><span class="line">OEXaQuS8IWkG19Xs</span><br><span class="line">$ service mysql status</span><br><span class="line">$ service mysql start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 MySQL-client</span></span><br><span class="line">$ rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm</span><br><span class="line"><span class="comment"># 修改 root 密码</span></span><br><span class="line">$ mysql -uroot -pOEXaQuS8IWkG19Xs</span><br><span class="line">mysql&gt;SET PASSWORD=PASSWORD(<span class="string">'123456'</span>);</span><br><span class="line">mysql&gt;<span class="built_in">exit</span></span><br></pre></td></tr></table></figure><ul><li>配置 MySQL 远程登录</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ mysql -uroot -p123456</span><br><span class="line">mysql&gt; use mysql;</span><br><span class="line">mysql&gt; show tables;</span><br><span class="line">mysql&gt; select User, Host, Password from user;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改 user 表，把 Host 表内容修改为%</span></span><br><span class="line">mysql&gt; update user <span class="built_in">set</span> host=<span class="string">'%'</span> <span class="built_in">where</span> host=<span class="string">'localhost'</span>;</span><br><span class="line"><span class="comment"># 其他的都删掉</span></span><br><span class="line">mysql&gt; delete from user <span class="built_in">where</span> host=<span class="string">'hadoop102'</span>;</span><br><span class="line">mysql&gt; delete from user <span class="built_in">where</span> host=<span class="string">'127.0.0.1'</span>;</span><br><span class="line">mysql&gt; delete from user <span class="built_in">where</span> host=<span class="string">'::1'</span>;</span><br><span class="line"></span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">mysql&gt; quit;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 都做完切换回原来的用户</span></span><br></pre></td></tr></table></figure><h4 id="7-2-2-修改-hive-元数据库"><a href="#7-2-2-修改-hive-元数据库" class="headerlink" title="7.2.2 修改 hive 元数据库"></a>7.2.2 修改 hive 元数据库</h4><ul><li>拷贝驱动</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp mysql-connector-java-5.1.27-bin.jar /opt/module/hive-2.3.0-bin/lib/</span><br></pre></td></tr></table></figure><ul><li>配置 Metastore 到 MySQL</li></ul><p>创建 <code>conf/hive-site.xml</code> </p><blockquote><p>官方配置文档<br><a href="https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+Administration" target="_blank" rel="noopener">AdminManual Metastore Administration - Apache Hive - Apache Software Foundation</a></p></blockquote><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop102:3306/metastore?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>启动</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初试化hive库</span></span><br><span class="line">$ bin/schematool -initSchema -dbType mysql</span><br><span class="line"><span class="comment"># 启动metastore节点</span></span><br><span class="line">$ nohup bin/hive --service metastore &amp;</span><br><span class="line"><span class="comment"># 启动hiveserver2（可选？） </span></span><br><span class="line">$ nohup bin/hive --service hiveserver2 &amp;</span><br><span class="line"><span class="comment"># 命令行启动</span></span><br><span class="line">$ bin/hive</span><br></pre></td></tr></table></figure><h3 id="7-3-Beeline-连接"><a href="#7-3-Beeline-连接" class="headerlink" title="7.3 Beeline 连接"></a>7.3 Beeline 连接</h3><blockquote><p>Hive学习之路 （四）Hive的连接3种连接方式 - 扎心了，老铁 - 博客园<br><a href="https://www.cnblogs.com/qingyunzong/p/8715925.html" target="_blank" rel="noopener">https://www.cnblogs.com/qingyunzong/p/8715925.html</a></p></blockquote><h3 id="7-4-常用交互命令"><a href="#7-4-常用交互命令" class="headerlink" title="7.4 常用交互命令"></a>7.4 常用交互命令</h3><p>1、<code>-e</code>不进入 hive 的交互窗口执行 sql 语句 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hive -e <span class="string">"select id from student;"</span></span><br></pre></td></tr></table></figure><p>2、<code>-f</code>执行脚本中 sql 语句 </p><ul><li>创建 hivef.sql 文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ touch hivef.sql</span><br><span class="line">select *from student;</span><br><span class="line">$ bin/hive -f xxx/hivef.sql &gt; xxx/result.txt</span><br></pre></td></tr></table></figure><h3 id="7-5-常用参数配置"><a href="#7-5-常用参数配置" class="headerlink" title="7.5 常用参数配置"></a>7.5 常用参数配置</h3><ul><li>查询后信息显示配置 <code>conf/hive-site.xml</code></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 可以显示表头列名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 显示当前数据库名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="八、HBase-配置"><a href="#八、HBase-配置" class="headerlink" title="八、HBase 配置"></a>八、HBase 配置</h2><h3 id="8-1-集群配置"><a href="#8-1-集群配置" class="headerlink" title="8.1 集群配置"></a>8.1 集群配置</h3><ul><li><code>conf/hbase-env.sh</code></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、注释掉下面两行</span></span><br><span class="line"><span class="comment"># Configure PermSize. Only needed in JDK7. You can safely remove it for JDK8+</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MASTER_OPTS=<span class="string">"<span class="variable">$HBASE_MASTER_OPTS</span> -XX:PermSize=128m -XX:MaxPermSize=128m"</span></span><br><span class="line"><span class="built_in">export</span> HBASE_REGIONSERVER_OPTS=<span class="string">"<span class="variable">$HBASE_REGIONSERVER_OPTS</span> -XX:PermSize=128m -XX:MaxPermSiz    e=128m"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、使用单独的 Zookeeper</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure><ul><li><code>conf/hbase-site.sh</code></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 都要根据自己的机器进行配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9000/HBase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/zookeeper-3.4.10/zkData<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>单独启动</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动 HDFS、Zookeeper</span></span><br><span class="line">$ start-dfs.sh</span><br><span class="line">$ <span class="variable">$&#123;Zookeeper_BASE&#125;</span>/bin/zkServer.sh start  <span class="comment"># 每个机器都要单独启动</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># HBase</span></span><br><span class="line">$ bin/hbase-daemon.sh start master   <span class="comment"># 在其中一台启动</span></span><br><span class="line">$ bin/hbase-daemon.sh start regionserver <span class="comment"># 都要启动</span></span><br><span class="line"></span><br><span class="line">$ bin/hbase-daemon.sh stop master   <span class="comment"># 在其中一台启动</span></span><br><span class="line">$ bin/hbase-daemon.sh stop regionserver <span class="comment"># 都要启动</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以在 hadoop102:16010 查看ui界面</span></span><br></pre></td></tr></table></figure><ul><li>群起 / 群停</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动 HDFS、Zookeeper</span></span><br><span class="line">$ start-dfs.sh</span><br><span class="line">$ <span class="variable">$&#123;Zookeeper_BASE&#125;</span>/bin/zkServer.sh start  <span class="comment"># 每个机器都要单独启动</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 conf/regionservers，添加所有 regionserver 的 host</span></span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br><span class="line"></span><br><span class="line"><span class="comment"># 群起 / 群停</span></span><br><span class="line">$ bin/start-hbase.sh</span><br><span class="line">$ bin/stop-hbase.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># regionservers</span></span><br><span class="line">$ bin/hbase-daemons.sh start regionserver</span><br><span class="line">$ bin/hbase-daemons.sh stop regionserver</span><br></pre></td></tr></table></figure><h3 id="8-2-常用操作"><a href="#8-2-常用操作" class="headerlink" title="8.2 常用操作"></a>8.2 常用操作</h3><p>使用 <code>help</code> 查看各种命令使用方式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出所有指令</span></span><br><span class="line">&gt; <span class="built_in">help</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看某一组命令的帮助</span></span><br><span class="line">&gt; <span class="built_in">help</span> <span class="string">'COMMAND_GROUP'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看单个命令帮助</span></span><br><span class="line">&gt; <span class="built_in">help</span> <span class="string">'COMMAND'</span></span><br></pre></td></tr></table></figure><h4 id="8-2-1-namespace"><a href="#8-2-1-namespace" class="headerlink" title="8.2.1 namespace"></a>8.2.1 namespace</h4><p><code>Commands: alter_namespace, create_namespace, describe_namespace, drop_namespace, list_namespace, list_namespace_tables</code></p><ul><li>list_namespace</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有库名</span></span><br><span class="line">&gt; list_namespace</span><br></pre></td></tr></table></figure><ul><li>create_namespace</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; create_namespace <span class="string">'school'</span></span><br></pre></td></tr></table></figure><ul><li>delete_namespace</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：只能删除空库</span></span><br><span class="line">&gt; delete_namespace <span class="string">'school'</span></span><br></pre></td></tr></table></figure><ul><li>list_namespace_tables</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出库中所有表</span></span><br><span class="line">&gt; list_namespace_tables <span class="string">'school'</span></span><br></pre></td></tr></table></figure><h4 id="8-2-2-DDL"><a href="#8-2-2-DDL" class="headerlink" title="8.2.2 DDL"></a>8.2.2 DDL</h4><p><code>Commands: alter, alter_async, alter_status, create, describe, disable, disable_all, drop, drop_all, enable, enable_all, exists, get_table, is_disabled, is_enabled, list, locate_region, show_filters</code></p><ul><li>list</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># list 列出所有表</span></span><br><span class="line">&gt; list</span><br></pre></td></tr></table></figure><ul><li>create</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create '库名:表名', &#123; NAME =&gt; '列族名1', 属性名 =&gt; 属性值&#125;, &#123;NAME =&gt; '列族名2', 属性名 =&gt; 属性值&#125;, …</span></span><br><span class="line">&gt; create <span class="string">'school:student'</span>, &#123;NAME=&gt;<span class="string">'info'</span>&#125;</span><br><span class="line">&gt; create <span class="string">'school:student'</span>, &#123;NAME=&gt;<span class="string">'info'</span>, VERSIONS=&gt;5&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果你只需要创建列族，而不需要定义列族属性，那么可以采用以下快捷写法：</span></span><br><span class="line"><span class="comment"># create'表名','列族名1' ,'列族名2', …</span></span><br><span class="line"><span class="comment"># 不写库名，默认 namespace 为 default</span></span><br><span class="line">&gt; create <span class="string">'student'</span>,<span class="string">'info'</span></span><br></pre></td></tr></table></figure><ul><li>desc</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; desc <span class="string">'student'</span></span><br></pre></td></tr></table></figure><ul><li>disable</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 停用表，防止对表进行写数据；在修改或删除表之前要 disable</span></span><br><span class="line">&gt; <span class="built_in">disable</span> <span class="string">'student'</span></span><br><span class="line">&gt; is_disable <span class="string">'student'</span></span><br></pre></td></tr></table></figure><ul><li>enable</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用表</span></span><br><span class="line">&gt; <span class="built_in">enable</span> <span class="string">'student'</span></span><br><span class="line">&gt; is_enable <span class="string">'student'</span></span><br></pre></td></tr></table></figure><ul><li>alter</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要先 disable</span></span><br><span class="line">&gt; alter <span class="string">'student'</span>, &#123;NAME =&gt; <span class="string">'info'</span>, VERSIONS =&gt; <span class="string">'5'</span>&#125;</span><br></pre></td></tr></table></figure><ul><li>drop</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要先 disable</span></span><br><span class="line">&gt; drop <span class="string">'student'</span></span><br></pre></td></tr></table></figure><ul><li>count</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看行数</span></span><br><span class="line">&gt; count <span class="string">'student'</span></span><br></pre></td></tr></table></figure><ul><li>truncate</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除表数据</span></span><br><span class="line">&gt; truncate <span class="string">'student'</span></span><br></pre></td></tr></table></figure><h4 id="8-2-3-DML"><a href="#8-2-3-DML" class="headerlink" title="8.2.3 DML"></a>8.2.3 DML</h4><p><code>Commands: append, count, delete, deleteall, get, get_counter, get_splits, incr, put, scan, truncate, truncate_preserve</code></p><ul><li>scan</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据</span></span><br><span class="line">&gt; scan <span class="string">'student'</span>, &#123;<span class="built_in">limit</span> =&gt; 5&#125;</span><br><span class="line"><span class="comment"># 查看每行最近十次修改的数据</span></span><br><span class="line">&gt; scan <span class="string">'student'</span>, &#123;RAW =&gt; <span class="literal">true</span>, VERSIONS =&gt; 10&#125;</span><br></pre></td></tr></table></figure><ul><li>put</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># put '表名', '行键', '列族:列名', '值'</span></span><br><span class="line">&gt; put <span class="string">'student'</span>, <span class="string">'1001'</span>, <span class="string">'info:name'</span>, <span class="string">'Nick'</span></span><br></pre></td></tr></table></figure><ul><li>get</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; get <span class="string">'student'</span>,<span class="string">'1001'</span></span><br></pre></td></tr></table></figure><ul><li>delete</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除某rowkey的全部数据：</span></span><br><span class="line">&gt; deleteall <span class="string">'student'</span>, <span class="string">'1001'</span></span><br><span class="line"><span class="comment"># 删除某rowkey的某一列数据：</span></span><br><span class="line">&gt; delete <span class="string">'student'</span>, <span class="string">'1002'</span>, <span class="string">'info:sex'</span></span><br></pre></td></tr></table></figure><h4 id="8-2-4-其他操作"><a href="#8-2-4-其他操作" class="headerlink" title="8.2.4 其他操作"></a>8.2.4 其他操作</h4><ul><li>flush</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将内存数据落盘</span></span><br><span class="line">&gt; flush <span class="string">'student'</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop, 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>vim 常用操作</title>
      <link href="/2020/09/17/Linux/vim%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
      <url>/2020/09/17/Linux/vim%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取消高亮</span></span><br><span class="line">:noh</span><br></pre></td></tr></table></figure><a id="more"></a><p>取消搜索后高亮</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># no high light search</span></span><br><span class="line">:nohlsearch</span><br><span class="line"><span class="comment"># 简写</span></span><br><span class="line">:noh</span><br></pre></td></tr></table></figure><p>移动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w <span class="comment"># 移至下一单词</span></span><br><span class="line">b <span class="comment"># 移至上一单词</span></span><br></pre></td></tr></table></figure><p>剪切、复制、粘贴、删除</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">dd <span class="comment"># 删除当前行</span></span><br><span class="line">5dd <span class="comment"># 删除5行</span></span><br><span class="line"></span><br><span class="line">yy <span class="comment"># 复制当前行</span></span><br><span class="line">5yy <span class="comment"># 复制5行</span></span><br><span class="line"></span><br><span class="line">p <span class="comment"># 粘贴</span></span><br></pre></td></tr></table></figure><p>设置 tab 键长度</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:<span class="built_in">set</span> tabstop=4</span><br></pre></td></tr></table></figure><p>开启自动缩进</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">:<span class="built_in">set</span> autoindent</span><br><span class="line">ctrl+d <span class="comment"># 停止自动缩进</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vim, 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>构建Hadoop的Docker编译环境</title>
      <link href="/2020/09/01/%E6%9E%84%E5%BB%BA%20Hadoop%20%E7%9A%84%20Docker%20%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/"/>
      <url>/2020/09/01/%E6%9E%84%E5%BB%BA%20Hadoop%20%E7%9A%84%20Docker%20%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h2 id="一、配置-docker-环境"><a href="#一、配置-docker-环境" class="headerlink" title="一、配置 docker 环境"></a>一、配置 docker 环境</h2><blockquote><p>参考链接：<br><a href="https://www.jianshu.com/p/0d3c17b4dddb" target="_blank" rel="noopener">Hadoop安装之一：使用Docker编译64位的Hadoop - 简书</a></p></blockquote><h3 id="1-制作-CentOS-7-基础镜像（可选）"><a href="#1-制作-CentOS-7-基础镜像（可选）" class="headerlink" title="1. 制作 CentOS 7 基础镜像（可选）"></a>1. 制作 CentOS 7 基础镜像（可选）</h3><p>Docker Hub上已经提供了<a href="https://link.jianshu.com?t=https://hub.docker.com/_/centos/" target="_blank" rel="noopener">CentOS7的官方镜像</a>，但并未激活 Systemd（用来启动守护进程），制作一个启动 Systemd 的镜像。（这里编译Hadoop其实用不到systemd）</p><ul><li>Dockerfile</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 镜像来源</span></span><br><span class="line">FROM centos:7</span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像创建者</span></span><br><span class="line">MAINTAINER <span class="string">"you"</span> &lt;your@email.here&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置一个环境变量</span></span><br><span class="line">ENV container docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行命令</span></span><br><span class="line"><span class="comment"># 设置systemd</span></span><br><span class="line">RUN (<span class="built_in">cd</span> /lib/systemd/system/sysinit.target.wants/; <span class="keyword">for</span> i <span class="keyword">in</span> *; <span class="keyword">do</span> [ <span class="variable">$i</span> == \</span><br><span class="line">systemd-tmpfiles-setup.service ] || rm -f <span class="variable">$i</span>; <span class="keyword">done</span>); \</span><br><span class="line">rm -f /lib/systemd/system/multi-user.target.wants/*;\</span><br><span class="line">rm -f /etc/systemd/system/*.wants/*;\</span><br><span class="line">rm -f /lib/systemd/system/<span class="built_in">local</span>-fs.target.wants/*; \</span><br><span class="line">rm -f /lib/systemd/system/sockets.target.wants/*udev*; \</span><br><span class="line">rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \</span><br><span class="line">rm -f /lib/systemd/system/basic.target.wants/*;\</span><br><span class="line">rm -f /lib/systemd/system/anaconda.target.wants/*;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载一个本地文件夹</span></span><br><span class="line">VOLUME [ <span class="string">"/sys/fs/cgroup"</span> ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置容器启动时的执行命令</span></span><br><span class="line">CMD [<span class="string">"/usr/sbin/init"</span>]</span><br></pre></td></tr></table></figure><ul><li>生成镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t centos7-systemd .</span><br></pre></td></tr></table></figure><h3 id="2-安装-Oracle-Java"><a href="#2-安装-Oracle-Java" class="headerlink" title="2. 安装 Oracle Java"></a>2. 安装 Oracle Java</h3><blockquote><p>参考链接<br><a href="https://blog.csdn.net/weixin_40651304/article/details/78833642" target="_blank" rel="noopener">使用yum卸载、安装jdk_不做小白的博客-CSDN博客</a></p></blockquote><p>注意不要使用 openjdk，会导致编译 hive 时出现问题</p><ul><li>启动刚刚生成的镜像</li><li>从官网下载 oracle java <code>jdk-8u202-linux-x64.tar.gz</code></li><li>安装 Java，配置环境变量</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/<span class="built_in">local</span>/java</span><br><span class="line">cp jdk-8u202-linux-x64.tar.gz /usr/<span class="built_in">local</span>/java</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/java</span><br><span class="line">tar -xzvf jdk-8u202-linux-x64.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line">~</span><br><span class="line">~</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/java/jdk1.8.0_202</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=/usr/<span class="built_in">local</span>/java/jdk1.8.0_202/jre  </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/<span class="built_in">local</span>/java/jdk1.8.0_202/bin  </span><br><span class="line"><span class="built_in">export</span> CLASSPATH=./:/usr/<span class="built_in">local</span>/java/jdk1.8.0_202/lib:/usr/<span class="built_in">local</span>/java/jdk1.8.0_202/jre/lib</span><br><span class="line">~</span><br><span class="line">~</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 JAVA 是否安装成功</span></span><br><span class="line">java -version</span><br></pre></td></tr></table></figure><ul><li>保存镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker commit 容器id 镜像名</span><br></pre></td></tr></table></figure><h3 id="3-制作编译镜像"><a href="#3-制作编译镜像" class="headerlink" title="3. 制作编译镜像"></a>3. 制作编译镜像</h3><ul><li>编译脚本</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ vi compile.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置默认编译版本(支持传参)</span></span><br><span class="line">version=<span class="variable">$&#123;1:-2.7.3&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入源代码目录</span></span><br><span class="line"><span class="built_in">cd</span> /hadoop-<span class="variable">$version</span>-src</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始编译</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">"\n\ncompile hadoop <span class="variable">$version</span>..."</span></span><br><span class="line">mvn clean package -Pdist,native -DskipTests -Dtar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line"><span class="keyword">if</span> [[ $? -eq 0]]; <span class="keyword">then</span></span><br><span class="line"> <span class="built_in">echo</span> -e <span class="string">"\n\ncompile hadoop <span class="variable">$version</span> success!\n\n"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"> <span class="built_in">echo</span> -e <span class="string">"\n\ncompile hadoop <span class="variable">$version</span> fail!\n\n"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><ul><li>Dockerfile（其中有不少安装包不是必要的）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 镜像来源(第二步生成的本地镜像)</span></span><br><span class="line">FROM centos7-systemd-java</span><br><span class="line"></span><br><span class="line"><span class="comment"># 镜像创建者</span></span><br><span class="line">MAINTAINER <span class="string">"you"</span> &lt;your@email.here&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行命令安装环境依赖</span></span><br><span class="line"><span class="comment"># 使用 -y 同意全部询问</span></span><br><span class="line">RUN yum update -y &amp;&amp; \</span><br><span class="line">    yum groupinstall -y <span class="string">"Development Tools"</span> &amp;&amp; \</span><br><span class="line">    yum install -y wget \</span><br><span class="line">               protobuf-devel \</span><br><span class="line">               protobuf-compiler \</span><br><span class="line">               maven \</span><br><span class="line">               cmake \</span><br><span class="line">               pkgconfig \</span><br><span class="line">               openssl-devel \</span><br><span class="line">               zlib-devel \</span><br><span class="line">               gcc \</span><br><span class="line">               automake \</span><br><span class="line">               autoconf \</span><br><span class="line">               make</span><br><span class="line">               </span><br><span class="line"><span class="comment"># 复制编辑脚本文件到镜像中</span></span><br><span class="line">COPY compile.sh /root/compile.sh</span><br><span class="line"><span class="comment"># 设置脚本文件的可运行权限</span></span><br><span class="line">RUN chmod +x /root/compile.sh</span><br></pre></td></tr></table></figure><ul><li>生成镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker build -t centos7-hadoop-compiler .</span><br></pre></td></tr></table></figure><h2 id="二、编译源码"><a href="#二、编译源码" class="headerlink" title="二、编译源码"></a>二、编译源码</h2><ul><li>hive（大概10分钟）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean package -Pdist -DskipTests</span><br></pre></td></tr></table></figure><ul><li>hadoop（大概15分钟）</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn clean package -Pdist,native -DskipTests -Dtar</span><br></pre></td></tr></table></figure><p>也可以使用 docker image 中的脚本编译</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> VERSION=2.7.3</span><br><span class="line">$ sudo docker run -v $(<span class="built_in">pwd</span>)/hadoop-<span class="variable">$VERSION</span>-src:/hadoop-<span class="variable">$VERSION</span>-src --privileged=<span class="literal">true</span>  centos7-hadoop-complier /root/compile.sh <span class="variable">$VERSION</span></span><br></pre></td></tr></table></figure><p><strong>要添加 privileged 参数！</strong></p><blockquote><p><a href="https://blog.csdn.net/halcyonbaby/article/details/43499409" target="_blank" rel="noopener">[docker]privileged参数_追寻神迹-CSDN博客</a></p></blockquote><p>使用该参数，container内的root拥有真正的root权限。<br>否则，container内的root只是外部的一个普通用户权限。</p><ul><li>总结</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pull docker image</span></span><br><span class="line">docker pull shuofxz/hadoop-compiler:1.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># === HADOOP ===</span></span><br><span class="line"><span class="comment"># hadoop download link</span></span><br><span class="line"><span class="comment"># new version</span></span><br><span class="line">https://hadoop.apache.org/releases.html</span><br><span class="line"><span class="comment"># old version</span></span><br><span class="line">https://archive.apache.org/dist/hadoop/common/</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile command (about 15 minutes to complete)</span></span><br><span class="line">mvn package -Pdist,native -DskipTests -Dtar</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile with script file</span></span><br><span class="line">$ <span class="built_in">export</span> VERSION=2.7.3</span><br><span class="line">$ sudo docker run -v $(<span class="built_in">pwd</span>)/hadoop-<span class="variable">$VERSION</span>-src:/hadoop-<span class="variable">$VERSION</span>-src --privileged=<span class="literal">true</span> shuofxz/hadoop-compiler:1.0 /root/hadoop-compile.sh <span class="variable">$VERSION</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># === HIVE ===</span></span><br><span class="line"><span class="comment"># hive download link</span></span><br><span class="line"><span class="comment"># select corresponding branch src file to download</span></span><br><span class="line">https://github.com/apache/hive</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile command (about 10 minutes to complete)</span></span><br><span class="line">mvn clean package -Pdist -DskipTests</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile with script file</span></span><br><span class="line">$ <span class="built_in">export</span> VERSION=2.3.0</span><br><span class="line">$ sudo docker run -v $(<span class="built_in">pwd</span>)/hive-rel-release-<span class="variable">$VERSION</span>:/hive-rel-release-<span class="variable">$VERSION</span> --privileged=<span class="literal">true</span> shuofxz/hadoop-compiler:1.0 /root/hive-compile.sh <span class="variable">$VERSION</span></span><br></pre></td></tr></table></figure><p>hadoop-2.7.0-src.tar.gz  release-2.3.0.tar.gz</p><hr><p>已包括各种库的 image，可以直接编译 hadoop（不好用）</p><p>GitHub - kiwenlau/compile-hadoop: Compile Hadoop in Docker container<br><a href="https://github.com/kiwenlau/compile-hadoop" target="_blank" rel="noopener">https://github.com/kiwenlau/compile-hadoop</a></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker,教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux压缩命令</title>
      <link href="/2020/09/01/Linux/Linux%E5%8E%8B%E7%BC%A9%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/09/01/Linux/Linux%E5%8E%8B%E7%BC%A9%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压 tar包</span></span><br><span class="line">tar -xvf file.tar </span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压tar.gz</span></span><br><span class="line">tar -xzvf file.tar.gz </span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.15版本后 tar 自动识别压缩方式</span></span><br><span class="line">tar -xvf filename.tar.gz</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="一、常用压缩参数"><a href="#一、常用压缩参数" class="headerlink" title="一、常用压缩参数"></a>一、常用压缩参数</h2><p><strong>必选参数，压缩解压都要用到其中一个：</strong></p><p>-c:  建立压缩档案</p><p>-x：解压</p><p>-t：查看内容</p><p>-r：向压缩归档文件末尾追加文件</p><p>-u：更新原压缩包中的文件</p><p><strong>可选参数：</strong></p><p>-z：有gzip属性的</p><p>-j： 有bz2属性的</p><p>-Z：有compress属性的</p><p>-v：显示所有过程</p><p>-O：将文件解开到标准输出</p><p><strong>下面的参数-f是必须的</strong></p><p>-f: 使用档案名字，切记，这个参数是最后一个参数，后面只能接档案名。</p><h2 id="二、举个栗子"><a href="#二、举个栗子" class="headerlink" title="二、举个栗子"></a>二、举个栗子</h2><p><strong>压缩</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将目录里所有jpg文件打包成tar.jpg</span></span><br><span class="line">tar -cvf jpg.tar *.jpg </span><br><span class="line"></span><br><span class="line"><span class="comment"># 将目录里所有jpg文件打包成jpg.tar后，并且将其用gzip压缩，生成一个gzip压缩过的包，命名为jpg.tar.gz</span></span><br><span class="line">tar -czf jpg.tar.gz *.jpg  </span><br><span class="line"></span><br><span class="line"><span class="comment"># rar格式的压缩，需要先下载rar for linux</span></span><br><span class="line">rar a jpg.rar *.jpg </span><br><span class="line"></span><br><span class="line"><span class="comment"># zip格式的压缩，需要先下载zip for linux</span></span><br><span class="line">zip jpg.zip *.jpg</span><br></pre></td></tr></table></figure><p><strong>解压</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 解压 tar包</span></span><br><span class="line">tar -xvf file.tar </span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压tar.gz</span></span><br><span class="line">tar -xzvf file.tar.gz </span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压 tar.bz2</span></span><br><span class="line">tar -xjvf file.tar.bz2  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压rar</span></span><br><span class="line">unrar e file.rar </span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压zip</span></span><br><span class="line">unzip file.zip</span><br></pre></td></tr></table></figure><p>从1.15版本开始tar就可以自动识别压缩的格式,故不需人为区分压缩格式就能正确解压</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf filename.tar.gz</span><br><span class="line">tar -xvf filename.tar.bz2</span><br><span class="line">tar -xvf filename.tar.xz</span><br><span class="line">tar -xvf filename.tar.Z</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux, 压缩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker 批量操作</title>
      <link href="/2020/08/28/Docker%20%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C/"/>
      <url>/2020/08/28/Docker%20%E6%89%B9%E9%87%8F%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi $(docker images | grep <span class="string">"none"</span> | awk <span class="string">'&#123;print $3&#125;'</span>)</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li>列出所有的容器 ID</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps -aq</span><br></pre></td></tr></table></figure><ul><li>停止所有的容器</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop $(docker ps -aq)</span><br></pre></td></tr></table></figure><ul><li>删除所有的容器</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm $(docker ps -aq)</span><br></pre></td></tr></table></figure><ul><li>删除所有的镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi $(docker images -q)</span><br></pre></td></tr></table></figure><ul><li>删除指定名称镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi $(docker images | grep <span class="string">"none"</span> | awk <span class="string">'&#123;print $3&#125;'</span>)</span><br></pre></td></tr></table></figure><ul><li>复制文件</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker cp mycontainer:/opt/file.txt /opt/local/</span><br><span class="line">docker cp /opt/local/file.txt mycontainer:/opt/</span><br></pre></td></tr></table></figure><p>现在的docker有了专门清理资源(container、image、网络)的命令。 </p><p>docker 1.13 中增加了 <code>docker system prune</code>的命令，针对container、image可以使用<code>docker container prune</code>、<code>docker image prune</code>命令。</p><ul><li>删除所有不使用的镜像</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker image prune --force --all</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">docker image prune -f -a</span><br></pre></td></tr></table></figure><ul><li>删除所有停止的容器</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker container prune -f</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cron语法</title>
      <link href="/2020/08/17/Linux/cron%E8%AF%AD%E6%B3%95/"/>
      <url>/2020/08/17/Linux/cron%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*   *    *   *   *   *  *</span><br><span class="line">秒 分钟  小时 天  月  星期 年</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="1-表达式详解"><a href="#1-表达式详解" class="headerlink" title="1 表达式详解"></a>1 表达式详解</h2><p>一个cron表达式有至少6个（也可能7个）有空格分隔的时间元素。</p><p>按顺序依次为</p><ul><li>1 秒（0~59）</li><li>2 分钟（0~59）</li><li>3 小时（0~23）</li><li>4 天（0~31）</li><li>5 月（0~11）</li><li>6 星期（1~7 1=SUN 或 SUN，MON，TUE，WED，THU，FRI，SAT）</li><li>7 年份（1970－2099）</li></ul><p>每个元素格式：</p><ul><li>一个具体值（如6）</li><li>一个连续区间（9-12）</li><li>一个列表(1,3,5)</li></ul><p>特殊字符</p><ul><li>通配符（*），所有可能的值</li><li>空符号（？），表示不指定值<ul><li>由于”月份中的日期”和”星期中的日期”这两个元素互斥的,必须要对其中一个设置?</li></ul></li><li>增量符（/）<ul><li>如第二位12/10 表示从第12分钟开始，每10分钟（它和“12，22，32…”）</li></ul></li><li>最后（L）<ul><li>仅被用于天（月）和天（星期）两个子表达式，它是单词“last”的缩写</li><li>“6L”表示这个月的倒数第６天</li></ul></li><li>平日（W）<ul><li>仅能用于日域中，它用来指定离指定日的最近的一个工作日（1-5）</li><li>日域中的 15W 意味着 “离该月15号的最近一个平日</li></ul></li></ul><h2 id="2-例子"><a href="#2-例子" class="headerlink" title="2 例子"></a>2 例子</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">0 0 10,14,16 * * ?  每天上午10点，下午2点，4点</span><br><span class="line">0 0/30 9-17 * * ?    朝九晚五工作时间内每半小时</span><br><span class="line">0 0 12 ? * WED  表示每个星期三中午12点</span><br><span class="line">0 0 12 * * ?  每天中午12点触发</span><br><span class="line">0 15 10 ? * *  每天上午10:15触发</span><br><span class="line">0 15 10 * * ? 2005 2005年的每天上午10:15触发</span><br><span class="line">0 * 14 * * ?   在每天下午2点到下午2:59期间的每1分钟触发</span><br><span class="line">0 0/5 14,18 * * ?  在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发</span><br><span class="line">0 0-5 14 * * ? 在每天下午2点到下午2:05期间的每1分钟触发</span><br><span class="line">0 10,44 14 ? 3 WED 每年三月的星期三的下午2:10和2:44触发</span><br><span class="line">0 15 10 ? * MON-FRI 周一至周五的上午10:15触发</span><br><span class="line">0 15 10 L * ? 每月最后一日的上午10:15触发</span><br><span class="line">0 15 10 ? * 6L 每月的最后一个星期五上午10:15触发</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cron </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo常用命令</title>
      <link href="/2020/08/13/Hexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/08/13/Hexo%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 生成静态文件</span></span><br><span class="line">hexo g</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动服务</span></span><br><span class="line">hexo s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 部署</span></span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><ul><li><strong>生成静态文件</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo generate</span><br><span class="line"><span class="meta">#</span><span class="bash"> 简写</span></span><br><span class="line">hexo g</span><br></pre></td></tr></table></figure><ul><li><strong>启动服务预览文章</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hexo server</span><br><span class="line"><span class="meta">#</span><span class="bash"> 简写</span></span><br><span class="line">hexo s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定端口</span></span><br><span class="line">hexo server -p 5000</span><br></pre></td></tr></table></figure><ul><li><strong>一键部署</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo deploy</span><br><span class="line"><span class="meta">#</span><span class="bash"> 简写</span></span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2020/08/12/Docker%E9%83%A8%E7%BD%B2Vue%E9%A1%B9%E7%9B%AE/"/>
      <url>/2020/08/12/Docker%E9%83%A8%E7%BD%B2Vue%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<p>[手把手系列之]Docker 部署 vue 项目 - 掘金<br><a href="https://juejin.im/post/6844903837774397447" target="_blank" rel="noopener">https://juejin.im/post/6844903837774397447</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/07/10/hello-world/"/>
      <url>/2020/07/10/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Mac安装node</title>
      <link href="/2020/07/10/Mac%E5%AE%89%E8%A3%85node/"/>
      <url>/2020/07/10/Mac%E5%AE%89%E8%A3%85node/</url>
      
        <content type="html"><![CDATA[<p>Mac安装及降级node版本</p><a id="more"></a><h2 id="1-安装最新版Node"><a href="#1-安装最新版Node" class="headerlink" title="1 安装最新版Node"></a>1 安装最新版Node</h2><ol><li>安装HomeBrew</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/ruby -e <span class="string">"<span class="variable">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)</span>"</span></span><br></pre></td></tr></table></figure><ol start="2"><li>安装Node</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install node</span><br></pre></td></tr></table></figure><ol start="3"><li>验证Node是否安装成功</li></ol><p>输入下面两条指令看是否可以都输出版本号</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure><h2 id="2-降级Node"><a href="#2-降级Node" class="headerlink" title="2 降级Node"></a>2 降级Node</h2><p>由于开发需要或版本兼容性，需要安装低版本的Node，按下面的方式操作</p><ol><li><p>卸载Node</p><p>如果你是按前面的方法安装的Node，则用下面的命令卸载</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew uninstall node</span><br></pre></td></tr></table></figure><ol start="2"><li>查看可用的Node版本</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew search node</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">==&gt; Formulae</span><br><span class="line">libbitcoin-node      node                 node-sass            node@12            nodebrew             nodenvllnode               node-build           node@10              node_exporter        nodeenv</span><br></pre></td></tr></table></figure><ol start="3"><li>安装你需要的版本</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里安装v12版本</span></span><br><span class="line">brew install node@12</span><br></pre></td></tr></table></figure><ol start="4"><li>连接Node</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">brew link node@12</span><br><span class="line"><span class="comment"># 这一步可能会报错, 按照提示执行命令就ok了, 比如我最后执行的是brew link --overwrite --force node@12</span></span><br></pre></td></tr></table></figure><ol start="5"><li>检查Node是否安装成功</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac使用代理ssh远程连接服务器 &amp; keep alive</title>
      <link href="/2020/07/10/%E9%85%8D%E7%BD%AE/Mac%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%20&amp;%20keep%20alive/"/>
      <url>/2020/07/10/%E9%85%8D%E7%BD%AE/Mac%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%20&amp;%20keep%20alive/</url>
      
        <content type="html"><![CDATA[<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接连接</span></span><br><span class="line">ssh -p 端口号 服务器用户名@ip地址</span><br><span class="line"><span class="comment"># eg: ssh -p 22 userkunyu@119.29.37.63</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过代理连接</span></span><br><span class="line">ssh -o ProxyCommand=<span class="string">"nc -X 5 -x 代理服务器ip:代理服务器端口 %h %p"</span> 需要访问的服务器的用户名@需要访问的服务器ip</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="1-直接连接"><a href="#1-直接连接" class="headerlink" title="1 直接连接"></a>1 直接连接</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh -p 端口号 服务器用户名@ip地址</span></span><br><span class="line">ssh -p 22 userkunyu@119.29.37.63</span><br></pre></td></tr></table></figure><h2 id="2-通过代理连接"><a href="#2-通过代理连接" class="headerlink" title="2 通过代理连接"></a>2 通过代理连接</h2><ol><li>直接连接</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ssh -o ProxyCommand="nc -X 5 -x 代理服务器ip:代理服务器端口 %h %p" 需要访问的服务器的用户名@需要访问的服务器ip</span></span><br><span class="line">ssh -o ProxyCommand=<span class="string">"nc -X 5 -x 192.168.0.255:9999 %h %p"</span> user_name@192.168.77.200</span><br></pre></td></tr></table></figure><ol start="2"><li>使用SSH配置文件</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi ~/.ssh/config</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Host *</span><br><span class="line">    ProxyCommand nc -X 5 -x 192.168.0.255:9999 %h %p</span><br></pre></td></tr></table></figure><p>配置好了之后就可以和直接连接一样使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh uesr@ip</span><br></pre></td></tr></table></figure><blockquote><p>Mac下SSH跳点连接及代理连接_Dawnworld-CSDN博客_mac ssh 代理<br><a href="https://blog.csdn.net/thundon/article/details/46858957" target="_blank" rel="noopener">https://blog.csdn.net/thundon/article/details/46858957</a></p></blockquote><h2 id="3-Keep-alive"><a href="#3-Keep-alive" class="headerlink" title="3 Keep alive"></a>3 Keep alive</h2><blockquote><p><a href="http://bluebiu.com/blog/iterm2-ssh-session-idle.html" target="_blank" rel="noopener">http://bluebiu.com/blog/iterm2-ssh-session-idle.html</a></p></blockquote><p><strong>方案一：</strong></p><p>在本机 <code>vim ~/.ssh/config</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 在开头添加</span><br><span class="line">Host *</span><br><span class="line">    ServerAliveInterval 60</span><br></pre></td></tr></table></figure><p>我觉得60秒就好了，而且基本去连的机器都保持，所以配置了<code>*</code>，如果有需要针对某个机器，可以自行配置为需要的<code>serverHostName</code>。</p><p><strong>方案二：</strong></p><p>单次连接</p><p>添加下面的参数</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -o ServerAliveInterval=30 user@host</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>iTerm2配置</title>
      <link href="/2020/07/10/%E9%85%8D%E7%BD%AE/iTerm2%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/07/10/%E9%85%8D%E7%BD%AE/iTerm2%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>iTerm2配置</p><p>Oh-my-zsh安装，主题配置</p><a id="more"></a><h2 id="1-安装iTerm2"><a href="#1-安装iTerm2" class="headerlink" title="1 安装iTerm2"></a>1 安装iTerm2</h2><p>iTerm2 是一款完全免费的，专为 Mac OS 用户打造的命令行应用。直接在官网上 <a href="http://iterm2.com/" target="_blank" rel="noopener">http://iterm2.com/</a> 下载并安装即可。</p><p>设置为默认终端</p><img src="https://raw.githubusercontent.com/shuopic/ImgBed/master/NoteImgs/Snipaste_2020-07-10_14-26-44.jpg" alt="Snipaste_2020-07-10_14-26-44" style="zoom: 33%;"><h2 id="2-安装-oh-my-zsh"><a href="#2-安装-oh-my-zsh" class="headerlink" title="2 安装 oh-my-zsh"></a>2 安装 oh-my-zsh</h2><p>bash是mac中terminal自带的shell，把它换成oh-my-zsh，这个的功能要多得多。拥有语法高亮，命令行tab补全，自动提示符，显示Git仓库状态等功能。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh -c <span class="string">"<span class="variable">$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)</span>"</span></span><br></pre></td></tr></table></figure><p><strong>解决权限问题</strong></p><p>如果安装完重启iterm之后，出现下面的提示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[oh-my-zsh] Insecure completion-dependent directories detected:</span><br><span class="line">drwxrwxrwx 7 hans admin 238 2 9 10:13 /usr/local/share/zsh</span><br><span class="line">drwxrwxrwx 6 hans admin 204 10 1 2017 /usr/local/share/zsh/site-functions</span><br><span class="line"></span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>解决方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod 755 /usr/<span class="built_in">local</span>/share/zsh</span><br><span class="line">chmod 755 /usr/<span class="built_in">local</span>/share/zsh/site-functions</span><br></pre></td></tr></table></figure><h2 id="3-配置主题"><a href="#3-配置主题" class="headerlink" title="3 配置主题"></a>3 配置主题</h2><h2 id="4-Vim配置"><a href="#4-Vim配置" class="headerlink" title="4 Vim配置"></a>4 Vim配置</h2><p>设置鼠标滚动</p><p><img src="https://raw.githubusercontent.com/shuopic/ImgBed/master/NoteImgs/image-20200710182315449.png" alt="image-20200710182315449"></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux后台执行命令</title>
      <link href="/2019/10/22/Linux/Linux%E5%90%8E%E5%8F%B0%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/"/>
      <url>/2019/10/22/Linux/Linux%E5%90%8E%E5%8F%B0%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p>当在终端工作时，可能一个持续运行的作业占住屏幕输出，或终端退出时导致命令结束。为了避免这些问题，可以将这些进程放到后台运行，且不受终端关闭的影响，可使用下面的方法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup command &gt; myout.file 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="1-后台执行命令"><a href="#1-后台执行命令" class="headerlink" title="1 后台执行命令"></a>1 后台执行命令</h2><h3 id="1-1-命令-amp"><a href="#1-1-命令-amp" class="headerlink" title="1.1 命令&amp;"></a>1.1 命令<code>&amp;</code></h3><p>在命令后面加上<code>&amp;</code>实现后台运行（控制台关掉(退出帐户时)，作业就会<strong>停止</strong>运行）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">command &amp;</span><br></pre></td></tr></table></figure><p>例：<code>python run.py &amp;</code></p><h3 id="1-2-命令nohup"><a href="#1-2-命令nohup" class="headerlink" title="1.2 命令nohup"></a>1.2 命令<code>nohup</code></h3><p><code>nohup</code>命令可以在你退出帐户之后继续运行相应的进程。nohup就是不挂起的意思( no hang up)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup command &amp;</span><br></pre></td></tr></table></figure><p>例：<code>nohup run.py &amp;</code></p><h2 id="2-kill进程"><a href="#2-kill进程" class="headerlink" title="2 kill进程"></a>2 kill进程</h2><p>执行后台任务命令后，会返回一个进程号，可通过这个进程号kill掉进程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill -9 进程号</span><br></pre></td></tr></table></figure><h2 id="3-输出重定向"><a href="#3-输出重定向" class="headerlink" title="3 输出重定向"></a>3 输出重定向</h2><p>由于使用前面的命令将任务放到后台运行，因此任务的输出也不打印到屏幕上了，所以需要将输出重定向到文件中，以方便查看输出内容。</p><ul><li>将输出重定向到 file（覆盖）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">command1 &gt; file1</span><br></pre></td></tr></table></figure><ul><li>将输出重定向到 file（追加）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">command1 &gt;&gt; file1</span><br></pre></td></tr></table></figure><ul><li>将 stdout 和 stderr 合并后重定向到 file<ul><li>2&gt;1代表什么，2与&gt;结合代表错误重定向，而1则代表错误重定向到一个文件1，而不代表标准输出；换成2&gt;&amp;1，&amp;与1结合就代表标准输出了，就变成错误重定向到标准输出.</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">command1 &gt; file1 2&gt;&amp;1</span><br></pre></td></tr></table></figure><p><strong>完整写法：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup command &gt;out.file 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h2 id="4-其他"><a href="#4-其他" class="headerlink" title="4 其他"></a>4 其他</h2><ul><li>nohup执行python程序时，print无法输出<ul><li>这是因为python的输出有缓冲，导致nohup.out并不能够马上看到输出</li><li>python 有个-u参数，使得python不启用缓冲</li><li><code>nohup python -u test.py &gt; nohup.out 2&gt;&amp;1 &amp;</code></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux统计文件夹下的文件数目</title>
      <link href="/2019/10/22/Linux/Linux%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6%E6%95%B0%E7%9B%AE/"/>
      <url>/2019/10/22/Linux/Linux%E7%BB%9F%E8%AE%A1%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B%E7%9A%84%E6%96%87%E4%BB%B6%E6%95%B0%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls -l | grep &quot;^-&quot; | wc -l</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="1-统计文件夹下的文件数目"><a href="#1-统计文件夹下的文件数目" class="headerlink" title="1 统计文件夹下的文件数目"></a>1 统计文件夹下的文件数目</h2><ul><li>统计当前目录下文件的个数（不包括目录）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls -l | grep &quot;^-&quot; | wc -l</span><br></pre></td></tr></table></figure><ul><li>统计当前目录下文件的个数（包括子目录）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls -lR| grep &quot;^-&quot; | wc -l</span><br></pre></td></tr></table></figure><ul><li>查看某目录下文件夹(目录)的个数（包括子目录）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls -lR | grep &quot;^d&quot; | wc -l</span><br></pre></td></tr></table></figure><p><strong>命令原理：</strong></p><ul><li><code>ls -l</code><ul><li>详细输出该文件夹下文件信息</li><li><code>ls -lR</code>是列出所有文件，包括子目录</li></ul></li><li><code>grep &quot;^-&quot;</code><ul><li>过滤<code>ls</code>的输出信息，只保留一般文件；只保留目录是<code>grep &quot;^d&quot;</code></li></ul></li><li><code>wc -l</code><ul><li>统计输出信息的行数</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python打印更详细的异常信息</title>
      <link href="/2019/10/21/Python%E6%89%93%E5%8D%B0%E6%9B%B4%E8%AF%A6%E7%BB%86%E7%9A%84%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF/"/>
      <url>/2019/10/21/Python%E6%89%93%E5%8D%B0%E6%9B%B4%E8%AF%A6%E7%BB%86%E7%9A%84%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF/</url>
      
        <content type="html"><![CDATA[<p>打印Python异常信息的几种方式</p><a id="more"></a><h2 id="1-简单的异常信息"><a href="#1-简单的异常信息" class="headerlink" title="1 简单的异常信息"></a>1 简单的异常信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    a = <span class="number">1</span>/<span class="number">0</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    print(e)</span><br></pre></td></tr></table></figure><p>打印最简单的message信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">division by zero</span><br></pre></td></tr></table></figure><h2 id="2-更完整的信息"><a href="#2-更完整的信息" class="headerlink" title="2 更完整的信息"></a>2 更完整的信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    a = <span class="number">1</span>/<span class="number">0</span></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    print(<span class="string">'str(e):\t'</span>, e)</span><br><span class="line">    print(<span class="string">'repr(e):\t'</span>, repr(e))</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'traceback.format_exc():\n%s'</span> % traceback.format_exc()) <span class="comment">#字符串</span></span><br><span class="line">    traceback.print_exc() <span class="comment">#执行函数</span></span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">str(e): division by zero</span><br><span class="line">repr(e): ZeroDivisionError(&apos;division by zero&apos;)</span><br><span class="line">traceback.format_exc():</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/ace/Play/test/异常信息.py&quot;, line 4, in &lt;module&gt;</span><br><span class="line">    a = 1/0</span><br><span class="line">ZeroDivisionError: division by zero</span><br><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/ace/Play/test/异常信息.py&quot;, line 4, in &lt;module&gt;</span><br><span class="line">    a = 1/0</span><br><span class="line">ZeroDivisionError: division by zero</span><br></pre></td></tr></table></figure><p><code>traceback.format_exc()</code>和<code>traceback.print_exc()</code>都可以打印完整的错误信息</p><p><code>traceback.format_exc()</code>返回值为字符串</p><p><code>traceback.print_exc()</code>是一个执行函数，直接在控制台打印错误信息</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python, 异常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【转】持续集成 Continuous Integration</title>
      <link href="/2019/10/18/%E9%85%8D%E7%BD%AE/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%20Continuous%20Integration/"/>
      <url>/2019/10/18/%E9%85%8D%E7%BD%AE/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%20Continuous%20Integration/</url>
      
        <content type="html"><![CDATA[<p><a href="https://easyhexo.com/1-Hexo-install-and-config/1-5-continuous-integration.html" target="_blank" rel="noopener">持续集成 Continuous Integration</a></p><a id="more"></a>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo多台电脑同步</title>
      <link href="/2019/10/16/Hexo%E5%A4%9A%E5%8F%B0%E7%94%B5%E8%84%91%E5%90%8C%E6%AD%A5/"/>
      <url>/2019/10/16/Hexo%E5%A4%9A%E5%8F%B0%E7%94%B5%E8%84%91%E5%90%8C%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<p>如果换了电脑该如何同步Hexo的源文件？把hexo文件从一个电脑cope到另外一个电脑吗？答案肯定不是这样的，因为这里面有好多依赖包，好几万个文件呢，这样显然不合理。</p><p>本文提供一种多台电脑同步源文件的方法。</p><a id="more"></a><h2 id="0-解决思路"><a href="#0-解决思路" class="headerlink" title="0 解决思路"></a>0 解决思路</h2><p>使用GitHub的分支！在博客对应的仓库中新建一个分支。一个分支用来存放Hexo生成的网站原始的文件，另一个分支用来存放生成的静态网页。</p><h2 id="1-创建分支"><a href="#1-创建分支" class="headerlink" title="1 创建分支"></a>1 创建分支</h2><h3 id="1-1-创建新分支"><a href="#1-1-创建新分支" class="headerlink" title="1.1 创建新分支"></a>1.1 创建新分支</h3><p>命令行操作：</p><p>GitHub操作：</p><p>点击branch按钮，输入新的分支名<code>source</code>，点创建。</p><h3 id="1-2-设置默认分支"><a href="#1-2-设置默认分支" class="headerlink" title="1.2 设置默认分支"></a>1.2 设置默认分支</h3><p>准备在<code>source</code>分支中存放源文件，<code>master</code>中存放生成的网页，因此将<code>source</code>设置为默认分支，方便同步文件。</p><p>在仓库<code>-&gt;Settings-&gt;Branches-&gt;Default branch</code>中将默认分支设为<code>source</code>，save保存</p><h2 id="2-源文件上传到GitHub"><a href="#2-源文件上传到GitHub" class="headerlink" title="2 源文件上传到GitHub"></a>2 源文件上传到GitHub</h2><ol><li>选好一个本地文件夹，执行</li></ol><p><code>git clone git@github.com:Simon-Ace/Simon-Ace.github.io.git(替换成你的仓库)</code></p><ol start="2"><li><p>在克隆到本地的<code>Simon-Ace.github.io</code>中，把除了.git 文件夹外的所有文件都删掉</p></li><li><p>把之前我们写的博客源文件全部复制过来，除了<code>.deploy_git</code></p></li></ol><p>复制过来的源文件应该有一个<code>.gitignore</code>，用来忽略一些不需要的文件，如果没有的话，自己新建一个，在里面写上如下，表示这些类型文件不需要git：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">Thumbs.db</span><br><span class="line">db.json</span><br><span class="line">*.log</span><br><span class="line">node_modules/</span><br><span class="line">public/</span><br><span class="line">.deploy*/</span><br></pre></td></tr></table></figure><p>注意，如果你之前克隆过theme中的主题文件，那么应该把主题文件中的<code>.git</code>文件夹删掉，因为git不能嵌套上传。</p><ol start="4"><li>提交更改</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit –m "add branch"</span><br><span class="line">git push</span><br></pre></td></tr></table></figure><hr><p>参考文章：</p><p><a href="https://juejin.im/post/5acf22e6f265da23994eeac9" target="_blank" rel="noopener">https://juejin.im/post/5acf22e6f265da23994eeac9</a></p><p><a href="https://www.zhihu.com/question/21193762" target="_blank" rel="noopener">https://www.zhihu.com/question/21193762</a></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python-加快pip安装速度</title>
      <link href="/2019/10/16/tutorials/Python-%E5%8A%A0%E5%BF%ABpip%E5%AE%89%E8%A3%85%E9%80%9F%E5%BA%A6/"/>
      <url>/2019/10/16/tutorials/Python-%E5%8A%A0%E5%BF%ABpip%E5%AE%89%E8%A3%85%E9%80%9F%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<p>PIP安装时使用国内镜像，加快下载速度</p><a id="more"></a><h2 id="0-国内源"><a href="#0-国内源" class="headerlink" title="0 国内源"></a>0 国内源</h2><p>清华：<a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><p>阿里云：<a href="http://mirrors.aliyun.com/pypi/simple/" target="_blank" rel="noopener">http://mirrors.aliyun.com/pypi/simple/</a></p><p>中国科技大学 <a href="https://pypi.mirrors.ustc.edu.cn/simple/" target="_blank" rel="noopener">https://pypi.mirrors.ustc.edu.cn/simple/</a></p><p>华中理工大学：<a href="http://pypi.hustunique.com/" target="_blank" rel="noopener">http://pypi.hustunique.com/</a></p><p>山东理工大学：<a href="http://pypi.sdutlinux.org/" target="_blank" rel="noopener">http://pypi.sdutlinux.org/</a> </p><p>豆瓣：<a href="http://pypi.douban.com/simple/" target="_blank" rel="noopener">http://pypi.douban.com/simple/</a></p><h2 id="1-临时使用"><a href="#1-临时使用" class="headerlink" title="1 临时使用"></a>1 临时使用</h2><p> 可以在使用pip的时候加参数<code>-i https://pypi.tuna.tsinghua.edu.cn/simple</code></p><p>例如：</p><p><code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple numpy</code></p><h2 id="2-永久修改"><a href="#2-永久修改" class="headerlink" title="2 永久修改"></a>2 永久修改</h2><p>这样就不用每次都添加国内镜像源地址了</p><p>Linux下，修改<code>~/.pip/pip.conf</code>（没有就创建一个文件夹及文件）</p><p>打开文件，添加内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="keyword">global</span>]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure><p> windows下，直接在user目录中创建一个pip目录，如：C:\Users\xx\pip，新建文件pip.ini，</p><p>内容同上</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一台电脑配置多个git账号</title>
      <link href="/2019/10/14/Linux/%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAgit%E8%B4%A6%E5%8F%B7/"/>
      <url>/2019/10/14/Linux/%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAgit%E8%B4%A6%E5%8F%B7/</url>
      
        <content type="html"><![CDATA[<h2 id="1-清除git全局设置"><a href="#1-清除git全局设置" class="headerlink" title="1 清除git全局设置"></a>1 清除git全局设置</h2><p>如果配置第一个账号的时候使用<code>git config --global</code>设置过，就先要取消掉，否则两个账号肯定会冲突</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 取消global</span></span><br><span class="line">git config --global --unset user.name</span><br><span class="line">git config --global --unset user.email</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="2-生成新账号的SSH-keys"><a href="#2-生成新账号的SSH-keys" class="headerlink" title="2 生成新账号的SSH keys"></a>2 生成新账号的SSH keys</h2><h3 id="2-1-用-ssh-keygen-命令生成密钥"><a href="#2-1-用-ssh-keygen-命令生成密钥" class="headerlink" title="2.1 用 ssh-keygen 命令生成密钥"></a>2.1 用 <code>ssh-keygen</code> 命令生成密钥</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ssh-keygen -t rsa -C <span class="string">"new email"</span></span></span><br></pre></td></tr></table></figure><p>平时都是直接回车，默认生成 <code>id_rsa</code> 和 <code>id_rsa.pub</code>。这里特别需要注意，出现提示输入文件名的时候(<code>Enter file in which to save the key (~/.ssh/id_rsa): id_rsa_new</code>)要输入与默认配置不一样的文件名，比如：我这里填的是 <code>id_rsa</code>和<code>id_rsa_me</code>。</p><p>如果之前没配置过ssh key，这里用不同邮箱生成两遍即可，注意用不同的文件名</p><p>成功后会出现：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Your identification has been saved in xxx.</span><br><span class="line">Your public key has been saved in xxx.</span><br></pre></td></tr></table></figure><h3 id="2-2-添加到ssh-agent中"><a href="#2-2-添加到ssh-agent中" class="headerlink" title="2.2 添加到ssh-agent中"></a>2.2 添加到ssh-agent中</h3><p>使用<code>ssh-add</code>将 IdentityFile 添加到 ssh-agent中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-add ~/.ssh/id_rsa</span><br><span class="line">ssh-add ~/.ssh/id_rsa_me</span><br></pre></td></tr></table></figure><h3 id="2-3-配置-ssh-config-文件"><a href="#2-3-配置-ssh-config-文件" class="headerlink" title="2.3 配置 ~/.ssh/config 文件"></a>2.3 配置 <code>~/.ssh/config</code> 文件</h3><p>在<code>~/.ssh/</code>下新建<code>config</code>文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The git info <span class="keyword">for</span> company</span></span><br><span class="line">Host git.XXX.com# git别名，写公司的git名字即可</span><br><span class="line">HostName git.XXX.com# git名字，同样写公司的git名字</span><br><span class="line">User git# 写 git 即可</span><br><span class="line">IdentityFile ~/.ssh/id_rsa        #私钥路径，若写错会连接失败</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The git info <span class="keyword">for</span> github</span></span><br><span class="line">Host github.com# git别名，写github的git名字即可</span><br><span class="line">HostName github.com        # git名字，同样写github的git名字</span><br><span class="line">User git# 写 git 即可</span><br><span class="line">IdentityFile ~/.ssh/id_rsa_me#私钥路径，若写错会连接失败</span><br></pre></td></tr></table></figure><h2 id="3-与GitHub链接"><a href="#3-与GitHub链接" class="headerlink" title="3 与GitHub链接"></a>3 与GitHub链接</h2><p>复制刚刚生成的两个ssh公钥到对应的账号中</p><p>文件<code>id_rsa.pub</code>中保存的就是 ssh 公钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pbcopy &lt; ~/.ssh/id_rsa.pub</span><br><span class="line">pbcopy &lt; ~/.ssh/id_rsa_me.pub</span><br></pre></td></tr></table></figure><p>在 github 网站中添加该 ssh 公钥</p><p>验证是否配置成功，以 github 为例，输入 <code>ssh -T git@github.com</code>，若出现</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hi xxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access.</span><br></pre></td></tr></table></figure><p>这样的字段，即说明配置成功。另一个同理。</p><blockquote><p>参考链接：</p><p>配置多个git账号的ssh密钥 - 掘金<br><a href="https://juejin.im/post/5befe84d51882557795cc8f9" target="_blank" rel="noopener">https://juejin.im/post/5befe84d51882557795cc8f9</a></p><p>同一台电脑配置多个git账号 · Issue #2 · jawil/notes<br><a href="https://github.com/jawil/notes/issues/2" target="_blank" rel="noopener">https://github.com/jawil/notes/issues/2</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
